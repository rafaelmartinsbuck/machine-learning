{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Projeto 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Esse é um problema de classificação usando aprendizagem supervisionada, pois os alunos estão sendo agrupados em duas categorias: aqueles que possam precisar de intervenção antecipada antes de serem reprovados e aqueles que podem não precisar. \n",
    "\n",
    "Adicionalmente, é um caso de machine learning onde os falsos positivos não são tão graves quanto aos falsos negativos, ou seja, identificar um aluno que não precisa de intervenção antecipada, mas mesmo assim oferecer recursos de suporte ao aprendizado não é tão grave quanto deixá-los de oferecer para um que precisava e não foi identificado pelo modelo. Essa premissa poderá ser importante para medir a precisão do modelo final a ser obtido.\n",
    "\n",
    "Exemplificando na *confusion matrix* abaixo, o que preferimos então é um alto recall (minimizar falsos negativos), mesmo que impacte um pouco na precisão (minimizar falsos positivos). No entanto, usar um F score de 1 já é uma boa, mas em trabalhos futuros poderiam-se utilizar F scores maiores (para considerar mais o *Recall* no score). Uma outra alternativa em vez de aumentar o valor de beta seria mudar a classe positiva para os alunos que não passaram (mudar pos_label para `'no'`) o que também acho que faria mais sentido.\n",
    "\n",
    "<img src=\"confusion_matrix.png\" width=\"50%\"/>\n",
    "\n",
    ">Machine learning's next trick is generating videos from photos ,URL: https://www.theverge.com/2016/9/12/12886698/machine-learning-video-image-prediction-mit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
      "0  ...         no       no       4         3      4    1    1      3        6   \n",
      "1  ...        yes       no       5         3      3    1    1      3        4   \n",
      "2  ...        yes       no       4         3      2    2    3      3       10   \n",
      "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
      "4  ...         no       no       4         3      2    1    2      5        4   \n",
      "\n",
      "  passed  \n",
      "0     no  \n",
      "1     no  \n",
      "2    yes  \n",
      "3    yes  \n",
      "4    yes  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 31 columns):\n",
      "school        395 non-null object\n",
      "sex           395 non-null object\n",
      "age           395 non-null int64\n",
      "address       395 non-null object\n",
      "famsize       395 non-null object\n",
      "Pstatus       395 non-null object\n",
      "Medu          395 non-null int64\n",
      "Fedu          395 non-null int64\n",
      "Mjob          395 non-null object\n",
      "Fjob          395 non-null object\n",
      "reason        395 non-null object\n",
      "guardian      395 non-null object\n",
      "traveltime    395 non-null int64\n",
      "studytime     395 non-null int64\n",
      "failures      395 non-null int64\n",
      "schoolsup     395 non-null object\n",
      "famsup        395 non-null object\n",
      "paid          395 non-null object\n",
      "activities    395 non-null object\n",
      "nursery       395 non-null object\n",
      "higher        395 non-null object\n",
      "internet      395 non-null object\n",
      "romantic      395 non-null object\n",
      "famrel        395 non-null int64\n",
      "freetime      395 non-null int64\n",
      "goout         395 non-null int64\n",
      "Dalc          395 non-null int64\n",
      "Walc          395 non-null int64\n",
      "health        395 non-null int64\n",
      "absences      395 non-null int64\n",
      "passed        395 non-null object\n",
      "dtypes: int64(13), object(18)\n",
      "memory usage: 95.7+ KB\n",
      "None\n",
      "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
      "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
      "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
      "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
      "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
      "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
      "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
      "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
      "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
      "\n",
      "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
      "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
      "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
      "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
      "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
      "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
      "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
      "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
      "\n",
      "         absences  \n",
      "count  395.000000  \n",
      "mean     5.708861  \n",
      "std      8.003096  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      4.000000  \n",
      "75%      8.000000  \n",
      "max     75.000000  \n",
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "# Obtendo algumas informações sobre o Dataset\n",
    "print(student_data.head())\n",
    "print(student_data.info())\n",
    "print(student_data.describe())\n",
    "\n",
    "print(\"Os dados dos estudantes foram lidos com êxito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7EAAAN8CAYAAACOVS0zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsREREREREdFv/A8FpfIVP40eswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11227ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avaliando uma correlação entre os últimos \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(student_data.iloc[:,25:], \n",
    "             palette = 'Set1', \n",
    "             hue = 'passed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEDCAYAAADUT6SnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsBdCCAfwf9rJoMOBLb1vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158efa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisando a relação entre idade de quem passou e de quem não passou, por sexo.\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    # Draw a nested violinplot and split the violins for easier comparison\n",
    "    sns.violinplot(x=\"sex\", \n",
    "                   y=\"age\", \n",
    "                   hue=\"passed\", \n",
    "                   data=student_data, \n",
    "                   split=True, \n",
    "                   inner=\"quart\", \n",
    "                   palette={\"yes\": \"b\", \"no\": \"r\"})\n",
    "    sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = student_data.shape[1] - 1 # desconsiderando a coluna de índice\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = student_data[student_data['passed']=='yes'].shape[0]\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = student_data[student_data['passed']=='no'].shape[0]\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = 100.*n_passed/n_students\n",
    "\n",
    "# Imprima os resultados\n",
    "print(\"Número total de estudantes: {}\".format(n_students))\n",
    "print(\"Número de atributos: {}\".format(n_features))\n",
    "print(\"Número de estudantes aprovados: {}\".format(n_passed))\n",
    "print(\"Número de estudantes reprovados: {}\".format(n_failed))\n",
    "print(\"Taxa de graduação: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observação: Dataset desbalanceado, importante fazer amostragem estratificada\n",
    "Como pode-se observar, esta base de dados é um pouco desbalanceada: 67% dos estudantes passaram e 33% reprovaram. Idealmente, esta proporção deve ser preservada para os novos subconjuntos de treino e teste. Durante o processo de divisão treino/teste cada valor de `'random_state'` acaba criando uma proporção diferente. Para que esta proporção seja preservada, devemos fazer uma amostragem estratificada. Em `'train_test_split'`, isto pode ser feito inserindo-se o parâmetro `'stratify=y_all'`. Desta forma, a apresentação de resultados será mais consistente com a realidade e teremos maior confiança sobre a influência de parâmetros no modelo final. A amostragem continua sendo aleatória, no entanto com a proporção de classes preservada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORFUN: Como a ideia é mapear os que não vão passar, e o dataset está desbalanceado, aqui um exemplo de inversão.\n",
    "# No entanto parece que, para esse problema, é melhor prever quem vai passar do quem não vai passar, ou seja\n",
    "#para 'yes' para 'passed' ou resultados ficarem melhores que 'no' para 'not_passed' (inversão do rótulo)\n",
    "#print(student_data['passed'].head())\n",
    "\n",
    "#student_data = student_data.rename(columns={'passed': 'not_passed'})\n",
    "#\n",
    "#student_data['not_passed'] = student_data['not_passed'].replace({'yes': 0, 'no': 1})\n",
    "#student_data['not_passed'] = student_data['not_passed'].replace({1: 'yes', 0: 'no'})\n",
    "#\n",
    "#print(student_data['not_passed'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "0     no\n",
      "1     no\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "Name: passed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1]) # n-1 atributos\n",
    "\n",
    "# Extraia a coluna-alvo 'passed'\n",
    "target_col = student_data.columns[-1] # 1 label\n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print(\"Colunas de atributos:\\n{}\".format(feature_cols))\n",
    "print(\"\\nColuna-alvo: {}\".format(target_col))\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())\n",
    "print(y_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (_dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção.\n",
    "\n",
    ">Binary encoding, URL: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
    "\n",
    ">Beyond One-Hot: an exploration of categorical variables, URL: https://www.kdnuggets.com/2015/12/beyond-one-hot-exploration-categorical-variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (39 total features):\n",
      "['school_MS', 'sex_M', 'age', 'address_U', 'famsize_LE3', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            # drop_first=True gera menos colunas sem perder informação\n",
    "            col_data = pd.get_dummies(col_data, \n",
    "                                      prefix = col, \n",
    "                                      drop_first=True)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_T</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob_health</th>\n",
       "      <th>Mjob_other</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_MS  sex_M  age  address_U  famsize_LE3  Pstatus_T  Medu  Fedu  \\\n",
       "0          0      0   18          1            0          0     4     4   \n",
       "1          0      0   17          1            0          1     1     1   \n",
       "2          0      0   15          1            1          1     1     1   \n",
       "3          0      0   15          1            0          1     4     2   \n",
       "4          0      0   16          1            0          1     3     3   \n",
       "\n",
       "   Mjob_health  Mjob_other    ...     higher  internet  romantic  famrel  \\\n",
       "0            0           0    ...          1         0         0       4   \n",
       "1            0           0    ...          1         1         0       5   \n",
       "2            0           0    ...          1         1         0       4   \n",
       "3            1           0    ...          1         1         1       3   \n",
       "4            0           1    ...          1         0         0       4   \n",
       "\n",
       "   freetime  goout  Dalc  Walc  health  absences  \n",
       "0         3      4     1     1       3         6  \n",
       "1         3      3     1     1       3         4  \n",
       "2         3      2     2     3       3        10  \n",
       "3         2      2     1     1       5         2  \n",
       "4         3      2     1     2       5         4  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Como pode ser observado, com o uso da função do Pandas get_dummies(), para cada dado categórico foi criada\n",
    "uma coluna, e atribuído o valor 0/1 dependendo de cada dado. Por exemplo, para cada dado categórico de Fjob foi\n",
    "criada uma coluna : Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher' e atribuído o \n",
    "valor 0/1'''\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "''' Aqui é importante observar essa divisão dos dados de treinamento e de teste(validação), uma boa regra de se \n",
    "aplicar para dividir os dados, conforme enunciado, é a Regra de Pareto 80/20.'''\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "# stratify=y_all para realizar uma amostragem estratificada, pois o Dataset está desbalanceado\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, \n",
    "                                                    y_all, \n",
    "                                                    train_size=num_train, \n",
    "                                                    stratify=y_all, \n",
    "                                                    random_state=50)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print(\"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0]))\n",
    "print(\"O conjunto de teste tem {} amostras.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml_map.png\"/>\n",
    "\n",
    "**Resposta: **Para lidar com o problema de **classificação**, os seguintes modelos são apropriados:Regressão Logística, Naive Bayes e SVM.\n",
    "\n",
    "### **Regressão Logística**\n",
    "- **Aplicação: **É um dos modelos mais simples de classificação, e funciona muito bem quando os dados são *linearmente separáveis*. Uma aplicação desse modelo é na classificação de alunos a serem aceitos ou não em uma universidade baseados em suas notas, por exemplo. Também pode ser usado em diversas aplicações médicas de diagnóstico e curiosamente prever medidas de segurança para minas de carvão.\n",
    "- **Vantagens: **\n",
    "    - As saídas têm uma boa interpretação probabilística e o algoritmo pode ser ajustado para evitar o overfitting; \n",
    "    - Os modelos logísticos podem ser atualizados facilmente com novos dados usando Método do gradiente estocástico (SGDC); \n",
    "    - Simples, funciona muito bem quando os dados são linearmente separáveis.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - O conjunto de dados do problema precisa ser linearmente separável; \n",
    "    - A regressão logística tende a ter uma performance inferior quando existem limites de decisão múltiplos ou não-lineares; \n",
    "    - Eles não são flexíveis o suficiente para capturar naturalmente relacionamentos mais complexos.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **A aplicação desse modelo para o problema é bastante promissora pois a Regressão Logística se aplica para problemas como o desse projeto (que inclusive se parece com o exemplificado), embora não dê para saber se os dados são linearmente separáveis. Isso somente será possível de avaliar durante os testes a seguir. Além disso, inspirando-se no princípio da *Navalha de Occam*, é bom começar com poucas premissas e com um modelo bem básico como referência para depois avaliar modelos mais complexos.\n",
    "\n",
    "<img src=\"logistic.png\" width=\"35%\"/>\n",
    "\n",
    "### **Gaussian Naive Bayes (GaussianNB)**\n",
    "- **Aplicação: **É um algoritmo muito simples em torno de probabilidade condicional e contagem. Basicamente é uma tabela de probabilidade, que se assemelha estruturalmente a uma Árvode de Decisão, atualizada com o treinamento. o Naive (que significa `\"ingênuo\"`) pois considera *independência dos dados* (dos atributos) o que raramente ocorre no mundo real. Esse modelo é bastante eficiente e utilizado em classificação de documentos (especialmente em classificação de SPAM, como é usado pelo Google no GMail), classificação de textos (como notícias que o usuário possa gostar em seu feed e *trend topics*), a sugestão de autocompletar em textos, como teclados de celular e *sentimental analysis* (de Tweets, por exemplo, identificando expressões negativas e positivas em textos). Assim como a Regressão Logística, tem sucesso em algumas aplicações médicas (prever doenças) e biológicas.\n",
    "- **Vantagens: **\n",
    "    - Funciona bem para Datasets com muitos atributos e quando os dados são categóricos;\n",
    "    - É um algoritmo muito rápido para treinamento;\n",
    "    - Como precisa de poucos parâmetros, é menos suscetível à overfitting;\n",
    "    - Separa bem o ruído nos dados.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Ele precisa de um Dataset moderado para treinamento;\n",
    "    - Os atributos precisam ser independentes entre si;\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Como o Dataset possui muitos atributos, e um número bom de dados (quase 400), parece ser interessante usar o Naive Bayes, até porque para verificar se é um bom modelo exigirá pouco esforço computacional. No entanto, não é possível saber se todas os atributos são independentes entre si, o que poderá ser verificado apenas com o resultado final da modelagem, comparando-se o score com os demais modelos.\n",
    "\n",
    "### **Máquinas de Vetores de Suporte (SVM)**\n",
    "- **Aplicação: **Esse modelo utiliza kernels, que aprendem a diferenciar duas categorias de dados com base em similaridades de exemplos passados, determinando uma borda de decisão que maximiza a distancia entre os membros mais próximos das categorias. Os exemplos de uso são parecidos com os da Regressão Logística, mas agora sem a restrição dos dados serem linearmente separáveis. São usados portanto em reconhecimento de escrita (mais do que Redes Neurais), reconhecimento facial, e classificação de imagens. Além disso, pode ser usado para prever dinâmicas de mercados e previsões financeiras.  \n",
    "- **Vantagens: **\n",
    "    - Consegue lidar com dados não-lineares;\n",
    "    - Não é necessário tomar premissas sobre o relacionamento entre os dados (como Regressão Logística e Naive Bayes o fazem);\n",
    "    - Geralmente resulta em modelos com melhor classificação de valores futuros;\n",
    "    - Possui diversos kernels;\n",
    "    - Bastante robusto contra overfitting, especialmente em espaços multi-dimensionais;\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Computacionalmente, exige bastante memória;\n",
    "    - Exige uma certa habilidade em escolher o melhor kernel para modelar a solução do probblema;\n",
    "    - Não escala muito bem bara grandes bases de dados;\n",
    "    - É mais utilizado como um classificador binário (que é como ele funciona melhor). Não funciona bem para problemas multi-classe;\n",
    "    - Atualmente, na indústria, tem-se preferido utilizar Random Forest ao invés de SVM.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Como o nosso problema é binário (\"passou\" ou \"não passou\"), o Dataset é de volume moderado, e não temos certeza se a Regressão Linear funcionará (ou seja, é uma alternativa boa se os dados não forem linearmente separáveis), o uso do SVM é interessante para esse problema. No entanto, escolher o melhor kernel deverá ser um ponto de atenção.\n",
    "\n",
    "<img src=\"svm.png\" width=\"35%\"/>\n",
    "\n",
    "No entanto, segue uma análise dos demais métodos.\n",
    "\n",
    "### **Árvores de Decisão (e suas variações: Gradient/Decision boosting, Random/Decision Forest )**\n",
    "- **Aplicação: **Também conhecidas como *Árvores de Classificação*, é um modelo bastante intuitivo graficamente ou programáticamente (através de *if-then statements*). Funciona muito bem quando os dados podem ser bem divididos a cada camada de decisão. Uma aplicação desse modelo é em que partido um eleitor vai votar, baseada em suas características como idade, sexo, classe social, etc. Ou, da mesma forma, é um excelente classificador para prever se um usuário vai assinar ou não um plano pago (*user signup*) de algum serviço ou até mesmo o funil/pipeline que o leva a tomar essa ação. Também pode ser utilizado para ranking, como no Netflix. Tem sido utilizado também com sucesso em problemas de reconhecimento de voz através de otimização e pruning de árvores. Tem aplicações também em sensoriamento remoto.\n",
    "- **Vantagens: **\n",
    "    - Devido à sua estrutura natural, escala bem e lida muito bem com dados não-lineares;\n",
    "    - Rápido de treinar e de visualizar o resultado e robusta a erros;\n",
    "    - Lida bem com dados categóricos e numéricos;\n",
    "    - Não é necessário tomar premissas sobre o relacionamento entre os dados (como Regressão Logística e Naive Bayes o fazem).\n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Podem crescer muito rápido de estrutura com Datasets grandes, causando overfitting (o que pode ser aliviado pelos métodos de *ensemble*);\n",
    "    - Geralmente resulta em modelos menos generalizados;\n",
    "    - Também usa bastante memória;\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Esse modelo, também simples, consegue lidar com dados que não são linearmente separáveis e categóricos. Além disso, existem muitos atributos cujos valores podem ser interpretados como \"0/1\" ou \"não/sim\", o que é perfeito para esse método. No entanto, ainda é uma dúvida se pelo tamanho do Dataset poderá resultar em um overfit ou ser serão necessárias técnicas de *ensemble* para contornar esse possível problema. \n",
    "\n",
    "<img src=\"tree.png\" width=\"35%\"/>\n",
    "\n",
    "### **Deep Learning (Redes Neurais)**\n",
    "- **Aplicação: **Inspirado no funcionamento do cérebro humano, esse clasificador de muitas maneiras faz a ponte entre o aprendizado de máquina e a ciência cognitiva, sendo bastante conveniente para classificação. Como principal aplicação do Deep Learning (utilizando MLP - *Multi Layer Perceptron* conectados por `\"sinapses\"`) temos o reconhecimento de imagens e de audio, principalmente com o aumento da capacidade de processamento de dados atual, bem como reconhecimento de movimento (andar, percurso de carros autônomos, voos de autônomos), também aplicações médicas, e até tradução de textos (Google Translator).\n",
    "- **Vantagens: **\n",
    "    - Possui muitos parâmetros se comparados aos outros métodos, o que lhe confere bastante versatilidade;\n",
    "    - Possui alta escalabilidade;\n",
    "    - Eficiente no uso de memória.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Pode tomar muito tempo e recursos computacionais para treinamento (para evitar *extremos locais* e outras situações típicas desse modelo);\n",
    "    - Precisa de bastante dados para treinamento;\n",
    "    - É uma caixa preta, ou seja, difícil de visualizar a estrutura final de uma rede neural;\n",
    "    - Alto nível de complexidade na modelagem.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Para esse problema, acho que iríamos cair em uma situação de `\"Matar uma mosca com uma bazooka\"`. Apesar de ser interessante usar uma Rede Neural para resolver esse problema, acredito que ele possa ser resolvido com métodos mais simples.\n",
    "\n",
    "<img src=\"nn.png\" width=\"35%\"/>\n",
    "\n",
    "### **K-Nearest Neighbors (K-NN)**\n",
    "- **Aplicação: **É uma classe de algoritmos especializados, denominada de *instance-based*, quando o problema exige uma objetivo bastante específico  ou uma *clusterização* do conjunto de dados, e utiliza funções que calculam similaridade dos dados com base em uma medida de *distância* entre eles. Geralmente é utilizada em aprendizagem não supervisionada, mas no campo da aprendizagem supervisionada uma aplicação bastante interessante para o K-NN é a detecção de anomalias nos dados (ou no modelo de agrupamento deles), como por exemplo detecção de fraudes e outras vulnerabilidades de segurança.\n",
    "- **Vantagens: **\n",
    "    - Consegue lidar com funções numericamente complexas;\n",
    "    - Útil quando o dado é difícil/caro de se obter, pois ao longo do processo de escala do modelo, pode-se revelar que dados são úteis ou não de se coletar.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Usam intensivamente a memória (muitas vezes até Bancos de Dados - *instance-based*);\n",
    "    - Requer todos os dados treinamento para realizar a previsão;\n",
    "    - Encontrar as funções de distância pode ser computacionalmente intensivo.\n",
    "    \n",
    "\n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **No problema em questão até poderia ser utilizado para clusterizar o Dataset e encontrar a função de distância que classificaria se um aluno precisa ou não dos recursos dado o grupo que se encaixa. No entanto, acredito que seja também uma situação de `\"Matar uma mosca com uma bazooka\"`.\n",
    "\n",
    "<img src=\"knn.png\" width=\"35%\"/>\n",
    "\n",
    ">Modern Machine Learning Algorithms: Strengths and Weaknesses, URL: https://elitedatascience.com/machine-learning-algorithms#classification\n",
    "\n",
    ">Machine Learning Algorithms for Business Applications – Complete Guide, URL: https://www.techemergence.com/machine-learning-algorithms-for-business-applications-complete-guide/\n",
    "\n",
    ">How to choose algorithms for Microsoft Azure Machine Learning, URL: https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice\n",
    "\n",
    ">Complete Guide to Parameter Tuning in XGBoost (with codes in Python), URL: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    ">Xgboost, URL: https://en.wikipedia.org/wiki/Xgboost\n",
    "\n",
    ">Machine Learning, do Vale do Silício ao Brasil, URL: https://www.youtube.com/watch?v=AJdoVmhAxUk&feature=youtu.be&t=1h37m28s\n",
    "\n",
    ">Installing XGBoost on Mac OSX, URL: https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_on_Mac_OSX?lang=en\n",
    "\n",
    ">XGBoost Installation Guide, URL: http://xgboost.readthedocs.io/en/latest/build.html#python-package-installation\n",
    "\n",
    ">How to Develop Your First XGBoost Model in Python with scikit-learn, URL: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print(\"O modelo foi treinado em {:.4f} segundos\".format(end - start))\n",
    "    return (end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print(\"As previsões foram feitas em {:.4f} segundos.\".format(end - start))\n",
    "    return (end - start), f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print(\"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_time = train_classifier(clf, X_train, y_train)\n",
    "    time, f1_score_train = predict_labels(clf, X_train, y_train)\n",
    "    test_time, f1_score_test = predict_labels(clf, X_test, y_test)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print(\"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(f1_score_train))\n",
    "    print(\"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(f1_score_test))\n",
    "    \n",
    "    return[clf.__class__.__name__, len(X_train), train_time, test_time, f1_score_train, f1_score_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression: \n",
      "\n",
      "Treinando um LogisticRegression com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0063 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9143.\n",
      "Pontuação F1 para o conjunto de teste: 0.8060.\n",
      "Treinando um LogisticRegression com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0028 segundos\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8459.\n",
      "Pontuação F1 para o conjunto de teste: 0.8201.\n",
      "Treinando um LogisticRegression com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0035 segundos\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8433.\n",
      "Pontuação F1 para o conjunto de teste: 0.7714.\n",
      "\n",
      "GaussianNB: \n",
      "\n",
      "Treinando um GaussianNB com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0013 segundos\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8148.\n",
      "Pontuação F1 para o conjunto de teste: 0.7402.\n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0017 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8129.\n",
      "Pontuação F1 para o conjunto de teste: 0.8000.\n",
      "Treinando um GaussianNB com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0025 segundos\n",
      "As previsões foram feitas em 0.0008 segundos.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.7914.\n",
      "Pontuação F1 para o conjunto de teste: 0.7852.\n",
      "\n",
      "SVC: \n",
      "\n",
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0035 segundos\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8933.\n",
      "Pontuação F1 para o conjunto de teste: 0.8182.\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0044 segundos\n",
      "As previsões foram feitas em 0.0026 segundos.\n",
      "As previsões foram feitas em 0.0014 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8704.\n",
      "Pontuação F1 para o conjunto de teste: 0.8243.\n",
      "Treinando um SVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0079 segundos\n",
      "As previsões foram feitas em 0.0058 segundos.\n",
      "As previsões foram feitas em 0.0019 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8772.\n",
      "Pontuação F1 para o conjunto de teste: 0.8026.\n",
      "\n",
      "LinearSVC: \n",
      "\n",
      "Treinando um LinearSVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0078 segundos\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9197.\n",
      "Pontuação F1 para o conjunto de teste: 0.7597.\n",
      "Treinando um LinearSVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0166 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8467.\n",
      "Pontuação F1 para o conjunto de teste: 0.8082.\n",
      "Treinando um LinearSVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0303 segundos\n",
      "As previsões foram feitas em 0.0006 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8356.\n",
      "Pontuação F1 para o conjunto de teste: 0.7778.\n",
      "\n",
      "MLPClassifier: \n",
      "\n",
      "Treinando um MLPClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.2201 segundos\n",
      "As previsões foram feitas em 0.0015 segundos.\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7576.\n",
      "Treinando um MLPClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0282 segundos\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.7491.\n",
      "Pontuação F1 para o conjunto de teste: 0.8000.\n",
      "Treinando um MLPClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0143 segundos\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8016.\n",
      "Pontuação F1 para o conjunto de teste: 0.7975.\n",
      "\n",
      "KNeighborsClassifier: \n",
      "\n",
      "Treinando um KNeighborsClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0046 segundos\n",
      "As previsões foram feitas em 0.0025 segundos.\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8497.\n",
      "Pontuação F1 para o conjunto de teste: 0.7808.\n",
      "Treinando um KNeighborsClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0011 segundos\n",
      "As previsões foram feitas em 0.0026 segundos.\n",
      "As previsões foram feitas em 0.0017 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8503.\n",
      "Pontuação F1 para o conjunto de teste: 0.7500.\n",
      "Treinando um KNeighborsClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0010 segundos\n",
      "As previsões foram feitas em 0.0051 segundos.\n",
      "As previsões foram feitas em 0.0024 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8526.\n",
      "Pontuação F1 para o conjunto de teste: 0.7692.\n",
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0015 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "As previsões foram feitas em 0.0005 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7287.\n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0016 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7244.\n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0024 segundos\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.6929.\n",
      "\n",
      "GradientBoostingClassifier: \n",
      "\n",
      "Treinando um GradientBoostingClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0809 segundos\n",
      "As previsões foram feitas em 0.0011 segundos.\n",
      "As previsões foram feitas em 0.0008 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7786.\n",
      "Treinando um GradientBoostingClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0922 segundos\n",
      "As previsões foram feitas em 0.0012 segundos.\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9888.\n",
      "Pontuação F1 para o conjunto de teste: 0.7576.\n",
      "Treinando um GradientBoostingClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.1001 segundos\n",
      "As previsões foram feitas em 0.0016 segundos.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9732.\n",
      "Pontuação F1 para o conjunto de teste: 0.8143.\n",
      "\n",
      "BaggingClassifier: \n",
      "\n",
      "Treinando um BaggingClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0338 segundos\n",
      "As previsões foram feitas em 0.0018 segundos.\n",
      "As previsões foram feitas em 0.0023 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9925.\n",
      "Pontuação F1 para o conjunto de teste: 0.7939.\n",
      "Treinando um BaggingClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0262 segundos\n",
      "As previsões foram feitas em 0.0031 segundos.\n",
      "As previsões foram feitas em 0.0020 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7287.\n",
      "Treinando um BaggingClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0268 segundos\n",
      "As previsões foram feitas em 0.0033 segundos.\n",
      "As previsões foram feitas em 0.0025 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9975.\n",
      "Pontuação F1 para o conjunto de teste: 0.7344.\n",
      "\n",
      "RandomForestClassifier: \n",
      "\n",
      "Treinando um RandomForestClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0175 segundos\n",
      "As previsões foram feitas em 0.0023 segundos.\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7460.\n",
      "Treinando um RandomForestClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0183 segundos\n",
      "As previsões foram feitas em 0.0019 segundos.\n",
      "As previsões foram feitas em 0.0027 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9850.\n",
      "Pontuação F1 para o conjunto de teste: 0.7059.\n",
      "Treinando um RandomForestClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0215 segundos\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "As previsões foram feitas em 0.0024 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9950.\n",
      "Pontuação F1 para o conjunto de teste: 0.6880.\n",
      "\n",
      "AdaBoostClassifier: \n",
      "\n",
      "Treinando um AdaBoostClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0939 segundos\n",
      "As previsões foram feitas em 0.0062 segundos.\n",
      "As previsões foram feitas em 0.0062 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9851.\n",
      "Pontuação F1 para o conjunto de teste: 0.7500.\n",
      "Treinando um AdaBoostClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0889 segundos\n",
      "As previsões foram feitas em 0.0070 segundos.\n",
      "As previsões foram feitas em 0.0085 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8509.\n",
      "Pontuação F1 para o conjunto de teste: 0.7634.\n",
      "Treinando um AdaBoostClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0931 segundos\n",
      "As previsões foram feitas em 0.0075 segundos.\n",
      "As previsões foram feitas em 0.0055 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8679.\n",
      "Pontuação F1 para o conjunto de teste: 0.7481.\n",
      "\n",
      "VotingClassifier: \n",
      "\n",
      "Treinando um VotingClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0029 segundos\n",
      "As previsões foram feitas em 0.0106 segundos.\n",
      "As previsões foram feitas em 0.0025 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9143.\n",
      "Pontuação F1 para o conjunto de teste: 0.8060.\n",
      "Treinando um VotingClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0044 segundos\n",
      "As previsões foram feitas em 0.0035 segundos.\n",
      "As previsões foram feitas em 0.0013 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8459.\n",
      "Pontuação F1 para o conjunto de teste: 0.8201.\n",
      "Treinando um VotingClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0065 segundos\n",
      "As previsões foram feitas em 0.0032 segundos.\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8433.\n",
      "Pontuação F1 para o conjunto de teste: 0.7714.\n",
      "\n",
      "SGDClassifier: \n",
      "\n",
      "Treinando um SGDClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0033 segundos\n",
      "As previsões foram feitas em 0.0014 segundos.\n",
      "As previsões foram feitas em 0.0006 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8024.\n",
      "Pontuação F1 para o conjunto de teste: 0.8050.\n",
      "Treinando um SGDClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0014 segundos\n",
      "As previsões foram feitas em 0.0004 segundos.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8075.\n",
      "Pontuação F1 para o conjunto de teste: 0.7846.\n",
      "Treinando um SGDClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0023 segundos\n",
      "As previsões foram feitas em 0.0008 segundos.\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.7654.\n",
      "Pontuação F1 para o conjunto de teste: 0.7786.\n",
      "\n",
      "XGBClassifier: \n",
      "\n",
      "Treinando um XGBClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0377 segundos\n",
      "As previsões foram feitas em 0.0025 segundos.\n",
      "As previsões foram feitas em 0.0022 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "Pontuação F1 para o conjunto de teste: 0.7910.\n",
      "Treinando um XGBClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0271 segundos\n",
      "As previsões foram feitas em 0.0035 segundos.\n",
      "As previsões foram feitas em 0.0016 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9708.\n",
      "Pontuação F1 para o conjunto de teste: 0.7704.\n",
      "Treinando um XGBClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0442 segundos\n",
      "As previsões foram feitas em 0.0027 segundos.\n",
      "As previsões foram feitas em 0.0019 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9454.\n",
      "Pontuação F1 para o conjunto de teste: 0.8029.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "# from sklearn import model_A\n",
    "# from sklearn import model_B\n",
    "# from skearln import model_C\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# FORFUN: Teste de demais classificadores\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "# Apresenta problema no classificador padrão para o Dataset com 200 dados de treino\n",
    "# from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = LogisticRegression()\n",
    "clf_B = GaussianNB()\n",
    "clf_C = SVC()\n",
    "\n",
    "# FORFUN: Inicialização dos demais modelos\n",
    "clf_D = LinearSVC()\n",
    "clf_E = MLPClassifier()\n",
    "clf_F = KNeighborsClassifier()\n",
    "clf_G = DecisionTreeClassifier()\n",
    "clf_H = GradientBoostingClassifier()\n",
    "clf_I = BaggingClassifier()\n",
    "clf_J = RandomForestClassifier()\n",
    "clf_K = AdaBoostClassifier()\n",
    "clf_L = VotingClassifier(estimators=[('lr', LogisticRegression())])\n",
    "clf_M = SGDClassifier()\n",
    "clf_N = XGBClassifier()\n",
    "\n",
    "df = pd.DataFrame(columns=['Classifier', 'Tamanho do Conjunto de Treinamento','Tempo de Treinamento','Tempo de Estimativa (teste)','Pontuação F1 (treinamento)','Pontuação F1 (teste)'])\n",
    "\n",
    "# TODO: Configure os tamanho dos conjuntos de treinamento\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train[:300]\n",
    "y_train_300 = y_train[:300]\n",
    "\n",
    "# TODO: Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E, clf_F, clf_G, clf_H, clf_I, clf_J, clf_K, clf_L, clf_M, clf_N]:\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for n in [100, 200, 300]:\n",
    "        register = train_predict(clf, X_train[:n], y_train[:n], X_test, y_test)\n",
    "        \n",
    "        # Monta a tabela\n",
    "        data = pd.DataFrame([register], columns=df.keys())\n",
    "        df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Tamanho do Conjunto de Treinamento</th>\n",
       "      <th>Tempo de Treinamento</th>\n",
       "      <th>Tempo de Estimativa (teste)</th>\n",
       "      <th>Pontuação F1 (treinamento)</th>\n",
       "      <th>Pontuação F1 (teste)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>100</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>300</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.843318</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.740157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.791367</td>\n",
       "      <td>0.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>300</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.759690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>200</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>300</td>\n",
       "      <td>0.030268</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.220142</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.749117</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.801603</td>\n",
       "      <td>0.797468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.092230</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.988848</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.973236</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.793893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.026809</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.997506</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.093878</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.088897</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.850909</td>\n",
       "      <td>0.763359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.093115</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.748092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.843318</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.805031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.807547</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.778626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.770370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.945368</td>\n",
       "      <td>0.802920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier Tamanho do Conjunto de Treinamento  \\\n",
       "0          LogisticRegression                                100   \n",
       "0          LogisticRegression                                200   \n",
       "0          LogisticRegression                                300   \n",
       "0                  GaussianNB                                100   \n",
       "0                  GaussianNB                                200   \n",
       "0                  GaussianNB                                300   \n",
       "0                         SVC                                100   \n",
       "0                         SVC                                200   \n",
       "0                         SVC                                300   \n",
       "0                   LinearSVC                                100   \n",
       "0                   LinearSVC                                200   \n",
       "0                   LinearSVC                                300   \n",
       "0               MLPClassifier                                100   \n",
       "0               MLPClassifier                                200   \n",
       "0               MLPClassifier                                300   \n",
       "0        KNeighborsClassifier                                100   \n",
       "0        KNeighborsClassifier                                200   \n",
       "0        KNeighborsClassifier                                300   \n",
       "0      DecisionTreeClassifier                                100   \n",
       "0      DecisionTreeClassifier                                200   \n",
       "0      DecisionTreeClassifier                                300   \n",
       "0  GradientBoostingClassifier                                100   \n",
       "0  GradientBoostingClassifier                                200   \n",
       "0  GradientBoostingClassifier                                300   \n",
       "0           BaggingClassifier                                100   \n",
       "0           BaggingClassifier                                200   \n",
       "0           BaggingClassifier                                300   \n",
       "0      RandomForestClassifier                                100   \n",
       "0      RandomForestClassifier                                200   \n",
       "0      RandomForestClassifier                                300   \n",
       "0          AdaBoostClassifier                                100   \n",
       "0          AdaBoostClassifier                                200   \n",
       "0          AdaBoostClassifier                                300   \n",
       "0            VotingClassifier                                100   \n",
       "0            VotingClassifier                                200   \n",
       "0            VotingClassifier                                300   \n",
       "0               SGDClassifier                                100   \n",
       "0               SGDClassifier                                200   \n",
       "0               SGDClassifier                                300   \n",
       "0               XGBClassifier                                100   \n",
       "0               XGBClassifier                                200   \n",
       "0               XGBClassifier                                300   \n",
       "\n",
       "   Tempo de Treinamento  Tempo de Estimativa (teste)  \\\n",
       "0              0.006324                     0.000598   \n",
       "0              0.002769                     0.000402   \n",
       "0              0.003540                     0.000525   \n",
       "0              0.001305                     0.000486   \n",
       "0              0.001722                     0.000425   \n",
       "0              0.002486                     0.000374   \n",
       "0              0.003475                     0.001273   \n",
       "0              0.004436                     0.001361   \n",
       "0              0.007929                     0.001900   \n",
       "0              0.007847                     0.000290   \n",
       "0              0.016561                     0.000330   \n",
       "0              0.030268                     0.000362   \n",
       "0              0.220142                     0.000680   \n",
       "0              0.028232                     0.000401   \n",
       "0              0.014349                     0.000456   \n",
       "0              0.004588                     0.001301   \n",
       "0              0.001083                     0.001713   \n",
       "0              0.000987                     0.002416   \n",
       "0              0.001545                     0.000524   \n",
       "0              0.001627                     0.000410   \n",
       "0              0.002390                     0.000652   \n",
       "0              0.080919                     0.000793   \n",
       "0              0.092230                     0.000750   \n",
       "0              0.100103                     0.000974   \n",
       "0              0.033793                     0.002321   \n",
       "0              0.026230                     0.002011   \n",
       "0              0.026809                     0.002453   \n",
       "0              0.017467                     0.001288   \n",
       "0              0.018292                     0.002662   \n",
       "0              0.021546                     0.002392   \n",
       "0              0.093878                     0.006227   \n",
       "0              0.088897                     0.008463   \n",
       "0              0.093115                     0.005470   \n",
       "0              0.002931                     0.002515   \n",
       "0              0.004422                     0.001271   \n",
       "0              0.006496                     0.002124   \n",
       "0              0.003293                     0.000591   \n",
       "0              0.001354                     0.000257   \n",
       "0              0.002342                     0.000332   \n",
       "0              0.037732                     0.002216   \n",
       "0              0.027140                     0.001606   \n",
       "0              0.044247                     0.001947   \n",
       "\n",
       "   Pontuação F1 (treinamento)  Pontuação F1 (teste)  \n",
       "0                    0.914286              0.805970  \n",
       "0                    0.845878              0.820144  \n",
       "0                    0.843318              0.771429  \n",
       "0                    0.814815              0.740157  \n",
       "0                    0.812950              0.800000  \n",
       "0                    0.791367              0.785185  \n",
       "0                    0.893333              0.818182  \n",
       "0                    0.870432              0.824324  \n",
       "0                    0.877193              0.802632  \n",
       "0                    0.919708              0.759690  \n",
       "0                    0.846667              0.808219  \n",
       "0                    0.835556              0.777778  \n",
       "0                    1.000000              0.757576  \n",
       "0                    0.749117              0.800000  \n",
       "0                    0.801603              0.797468  \n",
       "0                    0.849673              0.780822  \n",
       "0                    0.850340              0.750000  \n",
       "0                    0.852608              0.769231  \n",
       "0                    1.000000              0.728682  \n",
       "0                    1.000000              0.724409  \n",
       "0                    1.000000              0.692913  \n",
       "0                    1.000000              0.778626  \n",
       "0                    0.988848              0.757576  \n",
       "0                    0.973236              0.814286  \n",
       "0                    0.992481              0.793893  \n",
       "0                    1.000000              0.728682  \n",
       "0                    0.997506              0.734375  \n",
       "0                    1.000000              0.746032  \n",
       "0                    0.984962              0.705882  \n",
       "0                    0.995025              0.688000  \n",
       "0                    0.985075              0.750000  \n",
       "0                    0.850909              0.763359  \n",
       "0                    0.867925              0.748092  \n",
       "0                    0.914286              0.805970  \n",
       "0                    0.845878              0.820144  \n",
       "0                    0.843318              0.771429  \n",
       "0                    0.802395              0.805031  \n",
       "0                    0.807547              0.784615  \n",
       "0                    0.765432              0.778626  \n",
       "0                    1.000000              0.791045  \n",
       "0                    0.970803              0.770370  \n",
       "0                    0.945368              0.802920  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vizualizando o Benchmark final\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "SGDClassifier                 0.791791\n",
       "GaussianNB                    0.806377\n",
       "MLPClassifier                 0.850240\n",
       "KNeighborsClassifier          0.850874\n",
       "LinearSVC                     0.867310\n",
       "LogisticRegression            0.867827\n",
       "VotingClassifier              0.867827\n",
       "SVC                           0.880319\n",
       "AdaBoostClassifier            0.901303\n",
       "XGBClassifier                 0.972057\n",
       "GradientBoostingClassifier    0.987361\n",
       "RandomForestClassifier        0.993329\n",
       "BaggingClassifier             0.996662\n",
       "DecisionTreeClassifier        1.000000\n",
       "Name: Pontuação F1 (treinamento), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Média F1 Score para treinamento\n",
    "ranking = df.groupby(['Classifier'])['Pontuação F1 (treinamento)'].mean()\n",
    "ranking.sort_values(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier\n",
       "RandomForestClassifier        0.713305\n",
       "DecisionTreeClassifier        0.715335\n",
       "BaggingClassifier             0.752317\n",
       "AdaBoostClassifier            0.753817\n",
       "KNeighborsClassifier          0.766684\n",
       "GaussianNB                    0.775114\n",
       "LinearSVC                     0.781896\n",
       "GradientBoostingClassifier    0.783496\n",
       "MLPClassifier                 0.785015\n",
       "XGBClassifier                 0.788112\n",
       "SGDClassifier                 0.789424\n",
       "LogisticRegression            0.799181\n",
       "VotingClassifier              0.799181\n",
       "SVC                           0.815046\n",
       "Name: Pontuação F1 (teste), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Média F1 Score para teste (validação)\n",
    "ranking = df.groupby(['Classifier'])['Pontuação F1 (teste)'].mean()\n",
    "ranking.sort_values(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Tamanho do Conjunto de Treinamento</th>\n",
       "      <th>Tempo de Treinamento</th>\n",
       "      <th>Tempo de Estimativa (teste)</th>\n",
       "      <th>Pontuação F1 (treinamento)</th>\n",
       "      <th>Pontuação F1 (teste)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>100</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>300</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>200</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.973236</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.805031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>300</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.945368</td>\n",
       "      <td>0.802920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier Tamanho do Conjunto de Treinamento  \\\n",
       "0          LogisticRegression                                100   \n",
       "0          LogisticRegression                                200   \n",
       "0                         SVC                                100   \n",
       "0                         SVC                                200   \n",
       "0                         SVC                                300   \n",
       "0                   LinearSVC                                200   \n",
       "0  GradientBoostingClassifier                                300   \n",
       "0            VotingClassifier                                100   \n",
       "0            VotingClassifier                                200   \n",
       "0               SGDClassifier                                100   \n",
       "0               XGBClassifier                                300   \n",
       "\n",
       "   Tempo de Treinamento  Tempo de Estimativa (teste)  \\\n",
       "0              0.006324                     0.000598   \n",
       "0              0.002769                     0.000402   \n",
       "0              0.003475                     0.001273   \n",
       "0              0.004436                     0.001361   \n",
       "0              0.007929                     0.001900   \n",
       "0              0.016561                     0.000330   \n",
       "0              0.100103                     0.000974   \n",
       "0              0.002931                     0.002515   \n",
       "0              0.004422                     0.001271   \n",
       "0              0.003293                     0.000591   \n",
       "0              0.044247                     0.001947   \n",
       "\n",
       "   Pontuação F1 (treinamento)  Pontuação F1 (teste)  \n",
       "0                    0.914286              0.805970  \n",
       "0                    0.845878              0.820144  \n",
       "0                    0.893333              0.818182  \n",
       "0                    0.870432              0.824324  \n",
       "0                    0.877193              0.802632  \n",
       "0                    0.846667              0.808219  \n",
       "0                    0.973236              0.814286  \n",
       "0                    0.914286              0.805970  \n",
       "0                    0.845878              0.820144  \n",
       "0                    0.802395              0.805031  \n",
       "0                    0.945368              0.802920  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classificadores com F1 score de teste acima de 0,8\n",
    "df[df['Pontuação F1 (teste)'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Tamanho do Conjunto de Treinamento</th>\n",
       "      <th>Tempo de Treinamento</th>\n",
       "      <th>Tempo de Estimativa (teste)</th>\n",
       "      <th>Pontuação F1 (treinamento)</th>\n",
       "      <th>Pontuação F1 (teste)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Tamanho do Conjunto de Treinamento  Tempo de Treinamento  \\\n",
       "0        SVC                                200              0.004436   \n",
       "\n",
       "   Tempo de Estimativa (teste)  Pontuação F1 (treinamento)  \\\n",
       "0                     0.001361                    0.870432   \n",
       "\n",
       "   Pontuação F1 (teste)  \n",
       "0              0.824324  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maior F1 Score\n",
    "df[df['Pontuação F1 (teste)'] == df['Pontuação F1 (teste)'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **Baseados nos experimentos executados até o momento, **o melhor modelo para o sistema de intervenção de estudantes é o SVM**. Apesar de na média ele possuir os maiores tempos de treinamento e estimativa, os tempos ainda assim são baixos (menos de 1 centésimo de segundo). No entanto, ele apresenta as maiores Pontuações F1 para todos os tamanhos de conjunto de treinamento, se comparado com os outros dois modelos: GaussianNB e LogisticRegression. O SVM apresentou já no treinamento uma Pontuação F1 de **0,8803** na média, enquanto GaussianNB 0,8064 apresentou uma média de e LogisticRegression apresentou uma média de 0,8678. Mas o argumento mais determinante para selecionar o SVM como o modelo mais apropriado foi seu desempenho na generalização, ou seja, sua Pontuação F1 com os dados de teste (validação). O SVM apresentou uma Pontuação F1 de **0,8150** na média, enquanto GaussianNB 0,7751 apresentou uma média de e LogisticRegression apresentou uma média de 0,7992.\n",
    "\n",
    "É interessante notar que a LogisticRegression ficou em segundo lugar chegando perto do SVM, e superando GaussianNB. Muito provavelmente pois de certa forma o Dataset talvez seja *linearmente separável* de certa forma, e os dados são dependentes entre si, o que de fato aumenta com a realização da estratégia de conversão de variáveis categóricas com o `pandas.get_dummies()`, o que pode ter prejudicado o GaussianNB (gerou atributos a mais que são dependentes de outros, ou seja, os valores de `'Fjob_health'` dependem de certa forma dos de `'Fjob_other'` e dos outros que derivaram de `Fjob`, e assim por diante). Por fim, é interessante verificar o melhor desempenho no treinamento dos classificadores que usam árvore de decisão, porém com baixos desempenhos no treinamento, indicando uma maior influência do overfitting nesses modelos se comparados aos demais.\n",
    "\n",
    "Por fim, árvores de decisão melhoram considerávelmente após o processo de calibração. Talvez comparar vários estimadores em sua configuração padrão não seja o melhor critério para escolher o estimador à ser calibrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** As Máquinas de Vetores de Suporte (SVM, utilizam funções (chamadas *kernels*), que aprendem a diferenciar duas categorias de dados com base em similaridades de exemplos passados, determinando uma borda de decisão que maximiza a distancia entre os membros mais próximos das categorias. \n",
    "\n",
    "<img src=\"svm.png\" width=\"35%\"/>\n",
    "\n",
    "No nosso exemplo, esses dois grupos podem ser pensados como o grupo daqueles alunos que precisam de intervenção e o grupo daqueles que não precisam. O algoritmo do SVM (classificador na variável `'clf'`), então, buscou encontrar uma uma borda de decisão (acima representada por uma linha) que separasse os grupos da forma mais generalizada possível. E ele faz isso maximizando a distancia entre os membros mais próximos das categorias.\n",
    "\n",
    "Assim, para avaliar se um aluno pertence ao grupo daqueles alunos que precisam de intervenção ou ao grupo daqueles que não precisam, basta entrar com o vetor que representa as características desse aluno (X), ilustrado abaixo:\n",
    "\n",
    "`Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']`\n",
    "\n",
    "e utilizar a função `clf.predict(X)` e verificar qual o resultado produzido: `\"0\"` ele pertence ao grupo daqueles alunos que precisam de intervenção e `\"1\"` ele pertence ao grupo daqueles alunos que não precisam de intervenção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo (_Tuning_)\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2704 candidates, totalling 10816 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 988 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6088 tasks      | elapsed:   18.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo calibrado tem F1 de 0.9327 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8158 no conjunto de teste.\n",
      "O modelo calibrado tem Precisão de 0.7045 no conjunto de teste.\n",
      "O modelo calibrado tem Recall de 0.9688 no conjunto de teste.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10816 out of 10816 | elapsed:   38.5s finished\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar: nesse caso para o SVC\n",
    "kernel_range = ['linear','rbf','poly','sigmoid']\n",
    "C_range = np.logspace(-3, 3, 13)\n",
    "gamma_range = np.logspace(-4, 2, 13)\n",
    "random_state_range = [None,0,10,100]\n",
    "\n",
    "parameters = dict(gamma=gamma_range, C=C_range, kernel=kernel_range, random_state=random_state_range)\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = SVC()\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,\n",
    "                        pos_label=\"yes\")\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, parameters, \n",
    "                        cv=4, # The default grid search uses 3 folds; use the 'cv' param to change this\n",
    "                        scoring=f1_scorer, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)\n",
    "\n",
    "''' É altamente recomendável que se normalize os atributos antes de utilizá-los como entrada no modelo. \n",
    "Isso é especialmente verdade em modelos lineares como SVM e LR. O sklearn.preprocessing tem várias soluções \n",
    "para este propósito. '''\n",
    "# FORFUN: Normalizando dados (http://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "from sklearn.preprocessing import normalize\n",
    "X_train_norm = normalize(X_train)\n",
    "X_test_norm = normalize(X_test)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train_norm, \n",
    "                        y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetros\n",
    "y_pred = clf.predict(X_train_norm)\n",
    "f1_score_train = f1_score(y_train.values, \n",
    "                          y_pred, \n",
    "                          pos_label='yes')\n",
    "\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(f1_score_train))\n",
    "\n",
    "y_pred = clf.predict(X_test_norm)\n",
    "f1_score_test = f1_score(y_test.values, \n",
    "                         y_pred, \n",
    "                         pos_label='yes')\n",
    "\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(f1_score_test))\n",
    "\n",
    "precision_score = precision_score(y_test.values, \n",
    "                                  y_pred, \n",
    "                                  pos_label='yes')\n",
    "\n",
    "recall_score = recall_score(y_test.values, \n",
    "                            y_pred, \n",
    "                            pos_label='yes')\n",
    "\n",
    "print(\"O modelo calibrado tem Precisão de {:.4f} no conjunto de teste.\".format(precision_score))\n",
    "print(\"O modelo calibrado tem Recall de {:.4f} no conjunto de teste.\".format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=31.622776601683793,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Classification Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.71      0.16      0.26        31\n",
      "        yes       0.70      0.97      0.82        64\n",
      "\n",
      "avg / total       0.71      0.71      0.64        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime o melhor estimador\n",
    "print(clf)\n",
    "\n",
    "# look at results\n",
    "print(\"\\nClassification Report\\n\")\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x113608da0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAFNCAYAAAA5Pan0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158b2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando a confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cm_test = confusion_matrix(y_test, clf.predict(X_test_norm))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_test, \n",
    "            annot=True, \n",
    "            cmap='Greys', \n",
    "            xticklabels=['No','Yes'], \n",
    "            yticklabels=['No','Yes'])\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se pela *Confusion Matrix* que o modelo apresenta um Recall e uma Precisão satisfatórios, especialmente o Recall.\n",
    " - F1 Score de 0,8158 no conjunto de testes\n",
    " - Recall = 62/(62+2) = 96,88%\n",
    " - Precisão = 62/(62+26) = 70,45%\n",
    " \n",
    "A confusion matrix mostra que o estimador está dando preferência à classificar a maioria dos alunos que não passaram como passaram. A correção de pos_label para `'no'` poderia melhorar este balanço, mas executando o trecho de código que inverte o rótulo de `'passed'` para `'not_passed'` resulta em soluções piores.\n",
    "\n",
    "Um exercício futuro seria pergar os outros classificadores que não foram priorizados, como o LinearSVC, MLPClassifier, VotingClassifier, SGDClassifier, BaggingClassifier, XGBClassifier e GradientBoostingClassifier e realizar a calibração desses modelos para verificar se é obtido um classificador melhor que o encontrado para o SVC. Abaixo, uma exemplo para outro desses classificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 160 candidates, totalling 640 fits\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=0, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=0, score=0.781818 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=0, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=0, score=0.841121 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=10, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=10, score=0.781818 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.1, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=10, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, random_state=10, score=0.841121 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=0, score=0.796460 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=0, score=0.800000 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=0, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=0, score=0.830189 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=10, score=0.796460 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=10, score=0.800000 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=10, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=4, random_state=10, score=0.830189 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=0, score=0.785047 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=0, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=0, score=0.819048 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=10, score=0.752294 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=10, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=10, score=0.735849 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, random_state=10, score=0.819048 -   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.796460 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.800000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.841121 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=10, score=0.796460 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=10, score=0.800000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=6, random_state=10, score=0.841121 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=0, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=0, score=0.788991 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=0, score=0.819048 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=10, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=10, score=0.788991 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=7, random_state=10, score=0.819048 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=0, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=0, score=0.785714 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=0, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=10, score=0.785714 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=8, random_state=10, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=0, score=0.767857 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=0, score=0.788991 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=0, score=0.822430 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=10, score=0.767857 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=10, score=0.788991 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=10, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.1, max_depth=9, random_state=10, score=0.822430 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=0, score=0.738739 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=0, score=0.800000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=0, score=0.830189 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=10, score=0.738739 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=10, score=0.800000 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, random_state=10 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, random_state=10, score=0.830189 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=0, score=0.754386 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=0, score=0.770642 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=0, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=0, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=10, score=0.754386 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=10, score=0.770642 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=10, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, random_state=10, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=0, score=0.761062 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=0, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=0, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=0, score=0.811321 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=10, score=0.761062 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=10, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=4, random_state=10, score=0.811321 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=0, score=0.778761 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=0, score=0.735849 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=0, score=0.822430 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=10, score=0.778761 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=10, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=10, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, random_state=10, score=0.822430 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=0, score=0.732143 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=0, score=0.792793 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=0, score=0.728972 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=0, score=0.819048 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=10, score=0.732143 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=10, score=0.792793 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=10, score=0.728972 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=6, random_state=10, score=0.819048 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=0, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=0, score=0.826923 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=7, random_state=10, score=0.826923 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=0, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=0, score=0.815534 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=10, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=8, random_state=10, score=0.815534 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=0, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=0, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=10, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=10 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=9, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.2, max_depth=9, random_state=10, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=0, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=0, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=0, score=0.807692 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=10, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, random_state=10, score=0.807692 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=0, score=0.754386 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=0, score=0.693069 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=0, score=0.769231 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=10, score=0.754386 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=10, score=0.693069 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=10, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=3, random_state=10, score=0.769231 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=0, score=0.792793 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=0, score=0.722222 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=0, score=0.814815 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=10, score=0.792793 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=10, score=0.722222 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=4, random_state=10, score=0.814815 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=0, score=0.767857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=0, score=0.761905 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=0, score=0.770642 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=0, score=0.769231 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=10, score=0.767857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=10, score=0.761905 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=10, score=0.770642 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=5, random_state=10, score=0.769231 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=0, score=0.789474 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=0, score=0.777778 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=0, score=0.830189 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=10, score=0.789474 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=10, score=0.777778 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=6, random_state=10, score=0.830189 -   0.0s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=0, score=0.789474 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=0, score=0.730769 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=0, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=0, score=0.838095 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=10, score=0.789474 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=10, score=0.730769 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=10, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=7, random_state=10, score=0.838095 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=0, score=0.736842 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=0, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=0, score=0.774775 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=0, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=10, score=0.736842 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=10, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=10 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.3, max_depth=8, random_state=10, score=0.774775 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=8, random_state=10, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=0, score=0.761062 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=0, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=10, score=0.761062 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.3, max_depth=9, random_state=10, score=0.811321 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=0, score=0.782609 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=0, score=0.803738 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=10, score=0.782609 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.3, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.3, max_depth=10, random_state=10, score=0.803738 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=0, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=0, score=0.757282 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=0, score=0.815534 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=10, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=10, score=0.757282 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=3, random_state=10, score=0.815534 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=0, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=0, score=0.830189 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=10, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=4, random_state=10, score=0.830189 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=0, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=0, score=0.711538 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=0, score=0.777778 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=0, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=10, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=10, score=0.711538 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=10, score=0.777778 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=5, random_state=10, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=0, score=0.756757 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=0, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=0, score=0.819048 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=10, score=0.756757 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=10, score=0.773585 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=10, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=6, random_state=10, score=0.819048 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=0, score=0.709091 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=0, score=0.766355 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=0, score=0.759259 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=0, score=0.838095 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=10, score=0.709091 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=10 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.4, max_depth=7, random_state=10, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=7, random_state=10, score=0.838095 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=0, score=0.733945 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=0, score=0.730769 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=0, score=0.833333 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=10, score=0.733945 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=10, score=0.730769 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=8, random_state=10, score=0.833333 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=0, score=0.715596 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=0, score=0.780952 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=0, score=0.740741 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=0, score=0.764706 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=10, score=0.715596 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=10, score=0.780952 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=10, score=0.740741 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.4, max_depth=9, random_state=10, score=0.764706 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=0, score=0.715596 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=0, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=0, score=0.823529 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=10, score=0.715596 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=10, score=0.788462 -   0.0s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.4, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.4, max_depth=10, random_state=10, score=0.823529 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=0, score=0.761062 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=0, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=0, score=0.796296 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=10, score=0.761062 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=10, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, random_state=10, score=0.796296 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=0, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=0, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=0, score=0.834951 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=10, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=10, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=4, random_state=10, score=0.834951 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=0, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=0, score=0.712871 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=0, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=0, score=0.833333 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=10, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=10, score=0.712871 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, random_state=10, score=0.833333 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=0, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=0, score=0.773585 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=0, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=0, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=10, score=0.740741 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=10, score=0.773585 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=10 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=6, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=6, random_state=10, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=0, score=0.810811 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=0, score=0.737864 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=0, score=0.833333 -   0.2s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=10, score=0.810811 -   0.2s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=10, score=0.737864 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=7, random_state=10, score=0.833333 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=0, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=0, score=0.759259 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=0, score=0.776699 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=10, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=10, score=0.759259 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=8, random_state=10, score=0.776699 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=0, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=0, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=0, score=0.716981 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=0, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=10, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=10, score=0.757282 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=10, score=0.716981 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.5, max_depth=9, random_state=10, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=0, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=0, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=0, score=0.769231 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=10, score=0.752294 -   0.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=10, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=10, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, random_state=10, score=0.769231 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=0, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=0, score=0.699029 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=0, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=0, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=10, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=10, score=0.699029 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=10, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=3, random_state=10, score=0.780952 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=0, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=0, score=0.712871 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=0, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=0, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=10, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=10, score=0.712871 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=10, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=4, random_state=10, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=0, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=0, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=0, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=0, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=10, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=10, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=10, score=0.723810 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=5, random_state=10, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=0 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.6, max_depth=6, random_state=0, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=0, score=0.725490 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=0, score=0.826923 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=10, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=10, score=0.725490 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=10, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=6, random_state=10, score=0.826923 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=0, score=0.781818 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=0, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=0, score=0.770642 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=0, score=0.833333 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=10, score=0.781818 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=10, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=10, score=0.770642 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=7, random_state=10, score=0.833333 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=0, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=0, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=0, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=0, score=0.819048 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=10, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=10, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=8, random_state=10, score=0.819048 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=0, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=0, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=0, score=0.807692 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=10, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=10, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.6, max_depth=9, random_state=10, score=0.807692 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=0, score=0.769231 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=0, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=0, score=0.807692 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=10, score=0.769231 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=10, score=0.705882 -   0.1s\n",
      "[CV] learning_rate=0.6, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.6, max_depth=10, random_state=10, score=0.807692 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=0, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=0, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=0, score=0.788991 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=0, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=10, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=10, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=10, score=0.788991 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=3, random_state=10, score=0.773585 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=0, score=0.738739 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=0, score=0.740000 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=0, score=0.811321 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=10, score=0.738739 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=10, score=0.740000 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=4, random_state=10, score=0.811321 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=0 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.7, max_depth=5, random_state=0, score=0.754386 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=0, score=0.761905 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=0, score=0.781818 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=0, score=0.823529 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=10, score=0.754386 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=10, score=0.761905 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=10, score=0.781818 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=5, random_state=10, score=0.823529 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=0, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=0, score=0.732673 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=0, score=0.756757 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=0, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=10, score=0.756757 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=10, score=0.732673 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=10, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=6, random_state=10, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=0, score=0.745455 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=0, score=0.764706 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=0, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=0, score=0.803922 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=10, score=0.745455 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=10, score=0.764706 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=10, score=0.737864 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=7, random_state=10, score=0.803922 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=0, score=0.764706 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=0, score=0.759259 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=0, score=0.784314 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=10, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=10, score=0.764706 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=10, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=8, random_state=10, score=0.784314 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=0, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=0, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=10, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=10, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.7, max_depth=9, random_state=10, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=0, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=0, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=0, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=10, score=0.752294 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=10, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.7, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.7, max_depth=10, random_state=10, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=0, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=0, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=0, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=10, score=0.759259 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=10, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=3, random_state=10, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=0, score=0.733945 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=0, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=0, score=0.750000 -   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.8, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=0, score=0.876190 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=10, score=0.733945 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=10, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=4, random_state=10, score=0.876190 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=0, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=0, score=0.714286 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=0, score=0.796117 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=10, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=10, score=0.714286 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=10, score=0.754717 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=5, random_state=10, score=0.796117 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=0, score=0.745455 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=0, score=0.730769 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=0, score=0.831683 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=10, score=0.745455 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=10, score=0.730769 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=6, random_state=10, score=0.831683 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=0, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=0, score=0.734694 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=0, score=0.740741 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=0, score=0.834951 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=10, score=0.756757 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=10, score=0.734694 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=10, score=0.740741 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=7, random_state=10, score=0.834951 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=0, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=0, score=0.830189 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=10, score=0.737864 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=8, random_state=10, score=0.830189 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=0, score=0.745455 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=0, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=0, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=0, score=0.788462 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=10, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=10, score=0.757282 -   0.1s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=10, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.8, max_depth=9, random_state=10, score=0.788462 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=0, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=0, score=0.764706 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=0, score=0.800000 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=10, score=0.745455 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=10, score=0.764706 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=10, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.8, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.8, max_depth=10, random_state=10, score=0.800000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=0, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=0, score=0.752475 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=0 ..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.9, max_depth=3, random_state=0, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=0, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=10, score=0.743363 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=10, score=0.752475 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=10, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=3, random_state=10, score=0.849057 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=0, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=0, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=0, score=0.826923 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=10, score=0.732143 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=10, score=0.718447 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=10, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=4, random_state=10, score=0.826923 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=0, score=0.733945 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=0, score=0.784314 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=10, score=0.733945 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=10, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=5, random_state=10, score=0.784314 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=0, score=0.763636 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=0, score=0.745098 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=0, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=0, score=0.807692 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=10, score=0.763636 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=10, score=0.745098 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=10, score=0.754717 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=6, random_state=10, score=0.807692 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=0, score=0.771930 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=0, score=0.752475 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=0, score=0.740000 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=0, score=0.815534 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=10, score=0.771930 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=10, score=0.752475 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=10, score=0.740000 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=7, random_state=10, score=0.815534 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=0, score=0.722222 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=0, score=0.776699 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=10, score=0.722222 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=10, score=0.747664 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=8, random_state=10, score=0.776699 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=0, score=0.722222 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=0, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=0, score=0.705882 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=0, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=10, score=0.722222 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=10, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=10, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=0.9, max_depth=9, random_state=10, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=0, score=0.722222 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=0, score=0.750000 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=0 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.9, max_depth=10, random_state=0, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=0, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=10, score=0.722222 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=10, score=0.750000 -   0.1s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=10, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=0.9, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=0.9, max_depth=10, random_state=10, score=0.792453 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=0, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=0, score=0.727273 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=0, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=0, score=0.761905 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=10, score=0.728972 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=10, score=0.727273 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=10, score=0.720000 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=3, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=3, random_state=10, score=0.761905 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=0, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=0, score=0.725490 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=0, score=0.679612 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=0, score=0.788462 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=10, score=0.747664 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=10, score=0.725490 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=10, score=0.679612 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=4, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=4, random_state=10, score=0.788462 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=0, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=0, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=0, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=0, score=0.823529 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=10, score=0.766355 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=10, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=10, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=5, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=5, random_state=10, score=0.823529 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=0, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=0, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=0, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=0, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=10, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=10, score=0.785047 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=10, score=0.737864 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=6, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=6, random_state=10, score=0.792453 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=0, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=0, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=0, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=0, score=0.849057 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=10, score=0.740741 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=10, score=0.705882 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=10, score=0.735849 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=7, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=7, random_state=10, score=0.849057 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=0, score=0.730435 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=0, score=0.666667 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=0, score=0.810811 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=10, score=0.730435 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=10, score=0.666667 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=8, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=8, random_state=10, score=0.810811 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=0, score=0.736842 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=0, score=0.725490 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=0, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=0 ..................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=0, score=0.810811 -   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=1.0, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=10, score=0.736842 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=10, score=0.725490 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=10, score=0.742857 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=9, random_state=10 .................\n",
      "[CV]  learning_rate=1.0, max_depth=9, random_state=10, score=0.810811 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=0, score=0.736842 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=0, score=0.693069 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=0, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=0 .................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=0, score=0.810811 -   0.0s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=10, score=0.736842 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=10, score=0.693069 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=10, score=0.742857 -   0.1s\n",
      "[CV] learning_rate=1.0, max_depth=10, random_state=10 ................\n",
      "[CV]  learning_rate=1.0, max_depth=10, random_state=10, score=0.810811 -   0.1s\n",
      "O modelo calibrado tem F1 de 1.0000 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.7368 no conjunto de teste.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed:   34.1s finished\n"
     ]
    }
   ],
   "source": [
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar: nesse caso para o SVC\n",
    "learning_rate_range = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.]\n",
    "random_state_range = [0,10]\n",
    "max_depth_range = [3,4,5,6,7,8,9,10]\n",
    "\n",
    "parameters = dict(learning_rate=learning_rate_range, random_state=random_state_range, max_depth=max_depth_range)\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,\n",
    "                        pos_label=\"yes\")\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, parameters, \n",
    "                        cv=4, # The default grid search uses 3 folds; use the 'cv' param to change this\n",
    "                        scoring=f1_scorer, \n",
    "                        verbose=5)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train, \n",
    "                        y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetros\n",
    "y_pred = clf.predict(X_train)\n",
    "f1_score_train = f1_score(y_train.values, \n",
    "                          y_pred, \n",
    "                          pos_label='yes')\n",
    "\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(f1_score_train))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "f1_score_test = f1_score(y_test.values, \n",
    "                         y_pred, \n",
    "                         pos_label='yes')\n",
    "\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(f1_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\n",
      "Classification Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.42      0.35      0.39        31\n",
      "        yes       0.71      0.77      0.74        64\n",
      "\n",
      "avg / total       0.62      0.63      0.62        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime o melhor estimador\n",
    "print(clf)\n",
    "\n",
    "# look at results\n",
    "print(\"\\nClassification Report\\n\")\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1154c6d30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAFNCAYAAAA5Pan0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ae8cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_test, \n",
    "            annot=True, \n",
    "            cmap='Greys', \n",
    "            xticklabels=['No','Yes'], \n",
    "            yticklabels=['No','Yes'])\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a *K-folds Cross Validation* (com 4 folds `'cv=4'`) com o conjunto de treino ele apresentou a melhor performance.\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.796460 -   0.1s\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.800000 -   0.1s\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.742857 -   0.1s\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0 ..................\n",
    "\n",
    "[CV]  learning_rate=0.1, max_depth=6, random_state=0, score=0.841121 -   0.1s\n",
    "\n",
    "Mas o *F1 Score* ainda ficou abaixo do SVC, mas o F1 score para `'no'` ficou melhor, e é oque é interessante para o problema, acertar mais `'no'` do que `'yes'`, e a média entre eles ficou parecida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **A Pontuação F1 do treinamento do modelo calibrado foi 0.8228, 6,2% menor que o não calibrado para o mesmo tamanho de conjunto de treinamento, que foi de 0.8772. No entanto, a Pontuação F1 do teste aumentou, passando de 0.8026 para 0.8158 para o mesmo tamanho de conjunto de testes (aumento de 1,6%). É possível perceber, então que reduziu-se o overfitting e aumentou-se a generalização, com o uso do modelo calibrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
