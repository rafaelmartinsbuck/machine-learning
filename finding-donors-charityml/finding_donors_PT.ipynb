{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizado Supervisionado\n",
    "## Projeto: Encontrando doadores para a *CharityML*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seja bem-vindo ao segundo projeto do Nanodegree Engenheiro de Machine Learning! Neste notebook, você receberá alguns códigos de exemplo e será seu trabalho implementar as funcionalidades adicionais necessárias para a conclusão do projeto. As seções cujo cabeçalho começa com **'Implementação'** indicam que o bloco de código posterior requer funcionalidades adicionais que você deve desenvolver. Para cada parte do projeto serão fornecidas instruções e as diretrizes da implementação estarão marcadas no bloco de código com uma expressão `'TODO'`. \n",
    "Por favor, leia cuidadosamente as instruções!\n",
    "\n",
    "Além de implementações de código, você terá de responder questões relacionadas ao projeto e à sua implementação. Cada seção onde você responderá uma questão terá um cabeçalho com o termo **'Questão X'**. Leia com atenção as questões e forneça respostas completas nas caixas de texto que começam com o termo **'Resposta:'**. A submissão do seu projeto será avaliada baseada nas suas resostas para cada uma das questões além das implementações que você disponibilizar.\n",
    "\n",
    ">**Nota:** Por favor, especifique QUAL A VERSÃO DO PYTHON utilizada por você para a submissão deste notebook. As células \"Code\" e \"Markdown\" podem ser executadas utilizando o atalho do teclado **Shift + Enter**. Além disso, as células \"Markdown\" podem ser editadas clicando-se duas vezes na célula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando\n",
    "\n",
    "Neste projeto, você utilizará diversos algoritmos de aprendizado supervisionado para modelar com precisão a remuneração de indivíduos utilizando dados coletados no censo americano de 1994. Você escolherá o algoritmo mais adequado através dos resultados preliminares e irá otimizá-lo para modelagem dos dados. O seu objetivo com esta implementação é construir um modelo que pode predizer com precisão se um indivíduo possui uma remuneração superior a $50,000. Este tipo de tarefa pode surgir em organizações sem fins lucrativos que sobrevivem de doações. Entender a remuneração de um indivíduo pode ajudar a organização o montante mais adequado para uma solicitação de doação, ou ainda se eles realmente deveriam entrar em contato com a pessoa. Enquanto pode ser uma tarefa difícil determinar a faixa de renda de uma pesssoa de maneira direta, nós podemos inferir estes valores através de outros recursos disponíveis publicamente. \n",
    "\n",
    "O conjunto de dados para este projeto se origina do [Repositório de Machine Learning UCI](https://archive.ics.uci.edu/ml/datasets/Census+Income) e foi cedido por Ron Kohavi e Barry Becker, após a sua publicação no artigo _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. Você pode encontrar o artigo de Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). Os dados que investigaremos aqui possuem algumas pequenas modificações se comparados com os dados originais, como por exemplo a remoção da funcionalidade `'fnlwgt'` e a remoção de registros inconsistentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Explorando os dados\n",
    "Execute a célula de código abaixo para carregas as bibliotecas Python necessárias e carregas os dados do censo. Perceba que a última coluna deste cojunto de dados, `'income'`, será o rótulo do nosso alvo (se um indivíduo possui remuneração igual ou maior do que $50,000 anualmente). Todas as outras colunas são dados de cada indívduo na base de dados do censo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass education_level  education-num  marital-status  \\\n",
       "0   39   State-gov       Bachelors           13.0   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country income  \n",
       "0            40.0   United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importe as bibliotecas necessárias para o projeto.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Permite a utilização da função display() para DataFrames.\n",
    "\n",
    "# Importação da biblioteca de visualização visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Exibição amigável para notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Carregando os dados do Censo\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Sucesso - Exibindo o primeiro registro\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Explorando os Dados\n",
    "\n",
    "Uma investigação superficial da massa de dados determinará quantos indivíduos se enquadram em cada grupo e nos dirá sobre o percentual destes indivúdos com remuneração anual superior à \\$50,000. No código abaixo, você precisará calcular o seguinte:\n",
    "- O número total de registros, `'n_records'`\n",
    "- O número de indivíduos com remuneração anual superior à \\$50,000, `'n_greater_50k'`.\n",
    "- O número de indivíduos com remuneração anual até \\$50,000, `'n_at_most_50k'`.\n",
    "- O percentual de indivíduos com remuneração anual superior à \\$50,000, `'greater_percent'`.\n",
    "\n",
    "** DICA: ** Você pode precisar olhar a tabela acima para entender como os registros da coluna `'income'` estão formatados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78%\n"
     ]
    }
   ],
   "source": [
    "# Número total de registros.\n",
    "n_records = data.shape[0]\n",
    "\n",
    "# Número de registros com remuneração anual superior à $50,000\n",
    "n_greater_50k = data[data['income'] == '>50K'].shape[0]\n",
    "\n",
    "# O número de registros com remuneração anual até $50,000\n",
    "n_at_most_50k = data[data['income'] == '<=50K'].shape[0]\n",
    "\n",
    "# O percentual de indivíduos com remuneração anual superior à $50,000\n",
    "greater_percent = n_greater_50k/float(n_records)*100\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Explorando as colunas **\n",
    "* **age**: contínuo. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: contínuo. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: contínuo. \n",
    "* **capital-loss**: contínuo. \n",
    "* **hours-per-week**: contínuo. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparando os dados\n",
    "Antes de que os dados possam ser utilizados como input para algoritmos de machine learning, muitas vezes eles precisam ser tratados, formatados e reestruturados — este processo é conhecido como **pré-processamento**. Felizmente neste conjunto de dados não existem registros inconsistentes para tratamento, porém algumas colunas precisam ser ajustadas. Este pré-processamento pode ajudar muito com o resultado e poder de predição de quase todos os algoritmos de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os principais desvios das colunas contínuas\n",
    "Um conjunto de dados pode conter ao menos uma coluna onde os valores tendem a se próximar para um único número, mas também podem conter registros com o mesmo atributo contendo um valor muito maior ou muito menor do que esta tendência. Algoritmos podem ser sensíveis para estes casos de distribuição de valores e este fator pode prejudicar sua performance se a distribuição não estiver normalizada de maneira adequada. Com o conjunto de dados do censo, dois atributos se encaixam nesta descrição: '`capital-gain'` e `'capital-loss'`.\n",
    "\n",
    "Execute o código da célula abaixo para plotar um histograma destes dois atributos. Repare na distribuição destes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xe8PUV9//HXmypFARUQAQUJEY1RRFQMRrEjFmKJwYh8\nwR410ai/iBXEFjVqIMYWJaASGzZEFBHBjhRFwEJRQEGagNKkz++PmcN3v4db9n6/99x2Xs/H4zzu\n2dk5u7O75+6cz87sbEopSJIkSVIfq813ASRJkiQtHgYQkiRJknozgJAkSZLUmwGEJEmSpN4MICRJ\nkiT1ZgAhSZIkqTcDCM2rJH+X5LtJLk3y5yTnJ/lykl07efZOUpL8xXyWdWV1yr/VNPkOaflKkluT\n/CnJL5J8PMnDVna5E3zmeTMs/yFJzutMb9XW+4KZLGdlyrUy27iQJFktyX8muagd0y9Pk3+9JK9L\n8pMkVye5PsmZST4wyu9/kv2TPHqC9BWO/VKX5B5tX5/d9v01SU5K8oYkG8x3+Ualc94pSW5KclmS\n7yV5U5JNVmG5E36vVrGs+w+Vt/sayf/Iypw3paVujfkugMZXkn8BDgQOBt4DXAtsAzwJeDTwjfkr\n3by5DHhqe78ecG9gT+CHSd5ZSnl9J+/XgIcBF81g+XtT/+8PnsFn3ko9TqO0NxOXa2W2cSF5JvAK\n4NXAj4DLJ8uYZDPgW8DdgQ8A3wduBO4LPA/YGXjgiMq5H/B24NtD6XNx7BeEJI8AjgAuBQ4CzgDW\nBHYCXgbcFfjXeSvg6B0CfIR6YfEu1O3+Z+BfkuxeSvnhSixzsu/VbHg4cMtQ2u9GsB5YufOmtKQZ\nQGg+vQb4cinl+Z20bwP/k2RcW8duLKWc0Jk+NsmHgPcDr0tySinlCwCllMuoAcdIJFm7lHJDKeXX\no1rHdEa9jXPgPu3vf5ZSbp0m7yeBzYCHlFLO7qQfl+SDwO6jKOBU5vPYz6UkGwGHA78EHltKubYz\n+5tJ3gv8zbwUbu5cOHTu+WqSg4DvAV9Mcq9SynXzVLaJ/LiUcvN8F2JlJVkTuLn4NF8tUuP6I00L\nw52BiyeaMd2PrSQ7JrkkyReT3KGlrdG6f/wqyQ1Jfp/kvYP5Lc/pST7Wmd4gyc1JLhha/g+SfL4z\nPe2yW757JflakutaN4ADgbVnslMm2BcF+DfgEuCVnXXdrntPkn9M8tPW9eKqtr0vbvOOBx4J7Nxp\n8j9+aFmPSPL5JH8EftzmTdaNZa0k70vtfnZdkiOHuxq1Ze4/lDboArX3DMrV3cY1k7wtyXlJbmx/\n39Yq5OF1vDjJAaldiP6Y5KtJthgqz6T7bCpJdk3yo9Sud39K7Xp3787884DBtt/S3eYJlvVg4DHA\nO4aCB6B+B0opX+7kn7V9kGTwA+YNnf2/f5s3Wfe1Pvt12mPfSd8zyc9Suw39IcknU1tkZry8JA9O\nckySy9ux+U1qADaVFwAbA/88FDwAUEq5tpRyTGcd6yZ5V5Jz2/4/N7Wb02qdPLu0sj01tVvUH9rr\nU0k2HNqOVyT5ZSvvlUlOTvK0zvzzkhwyXK7hfZLkL5N8qf1PXp/kt6n/zyt1sbCUcgnw/4BNgWd3\n1vP4JEe1439dkjOSvDrJ6t2ytbcTfa8enOTwJBe0bT4zyTuSrLMy5ZxIkq2THJZ6Hr4hyandfdry\n/EX7rp3b+a58KDWgHOQ5nsnPT/t3trO73Mn+b16a5N1Jfg/cAGw4g7LO6rGVVpVfPM2nE4FlSX4D\nfKWUclafDyV5PPAF4DDgZaWUQTP2p4CnAO8Cfki9+vtWYCvgGS3PccCTO4vbhdpNZPMkf1lKOSvJ\n+sCDqV1PBqZddpK1gGOAdahdHi4FXgw8vc92TaWUcmOSY4FnJlljoitvSR7eynkQtdJfDdiOVkkB\nL23zV2/lArhqaDGHAZ+mdr2Z7vzwOuBUYB9gE+Ad1Ku1f1VKuWkGm9enXF2HAs9q6/s+9crwG4B7\nAf84QRl/SO0CtAnw3rauXaDXPptQ6j06X6O2mP0DsD5wAPD9JNuXUi4Engb8C7X7w+Aelsmu6D+u\n/T1iqvV2zNo+aGX7Ecu7sACsEFBPYLpl9pbkRW29n23LvXvbrocm2aGUcs0MlrU+cDT13LI3cDX1\nf3S61oPHAReVUk7usY412jruSz0HnE7t7vMm6kWRVw995EDgSOpxuTfwbmrXm2Vtec+h7r8DqFf7\n1wHu35Y1U18DrgT+CfgDsDmwG6t2sfCbwM3ULnQfb2n3Ao4F/gu4HtiRGixvDOzb8kz1vboH9dxx\nCPUY/RXw5rbcPXqWa/Uk3elbBxeekmxJvQByKbXb2WXU/9MvJPm7Usrg/+zu1G5Pr6Tut3sBrweO\nYvn/7EzPT1N5A3AS8KK2vOtnUNZRHFtp5ZVSfPmalxfwl8BpQGmvP1B/vD5+KN/ebf5fAM+h/uB/\ny1Cev2159hpKf05L375NP61N37NN/yf1R9vZwItb2q4tz3YzXPYL2/ROnTyrAT9v6VtNsz8OAS6Y\nYv4723I2HdovW7Xp1wBXTLOO44HvT5A+WNb7JynXeZ3prVreXwCrddJ3bunP76QVYP+h5Q0+v/cM\nyjXYxvtNssw3tvT7D63j+KF8r2npd++7zybZjye378wanbStgZuA93XS3kZrRJpmeR9q5Vq7R95Z\n3Qed4/S2GRz7vsuc8thTf0RdAhw3lO/hLd+/zHB5O3b3wQyO5y+BH/XM+9y2jkcMpb+Bem7apE3v\n0vIdOpTvA9Qf3elM/2SadZ4HHDJB+m37hHqPRgGeuhLf5wmPf2f+RcDXJ5kX6sWGN1B/4K7Wd7lD\nn98TuBW4yzT592d5ndF9faqT5+PUH+J3GfrsMcCpUyx7jc5374Gd9OOZ+Py0PxP8f0/xf/OTwXGf\nSVlX5dj68jWql5Gr5k2pLQ4PpDYPv516ReppwNFJ3jjBR15JPTG/opSy39C8XamV9+Gp3Y3WaFcK\nv9nmP6L9PZ5aSQ1GBnk09Sryt4fSLiql/GqGy34Y8LvS6Udc6hWxz/XYHX0MLreVSeafBGzUukg8\nebibRE9fmkHew0unq1kp5QfUK4y3GzFqFg329aeG0gfTjxxKP2po+vT29x7t74z3WZL1gB2Az5ZO\nS1Ap5VzgBxOUYbbN9j5YGbO1zHtTWzAO6yaWUr4PnM/M9+XZwB+Bj6R2i9pyhp/vY1dq2X44wflg\ncNN119eGpk+ndmvctE2fBGyf5L+SPDbJuitZrsuB3wD/nuSFSbZdyeVMJHTOO0k2S/KRJOdTz403\nUYPlDanHc+qFJXdK7QL2a2pXnpuo9wAF6FvunagtxYPXmzrzdqV+R/80dIyOBh6Q5E6tHGsleX1q\n19Q/t3J8ry3j3sy+L5dShs/ffco6ymMrrRQDCM2rUsotpZTvllLeWEp5LLUJ+XRgv24/1GYP4EJq\n96VhmwBrUUdyuqnzurTNv0tb35XAz4BHJbkr9Wruce21S8v7qDY9o2VTb4C9ZIKyTZS2MrakVtZX\nTDSzlPId4O9bvi8BlyX5VpL7z2AdMxntaLJt3XwGy5ipQbeO4XJePDR/YHhf3dD+3gFWep9tRP2h\nM9G+uniCMvQxGD3mnj3yzuo+WEmztczJtgVWYl+WUv5E/f/9PfBB4Letf/4zpv4kv6Pfvod6Prgn\nK54LbqJ2m4Ll54OB6fbVJ6jdUh5K/dF4Req9XVv1LA9w271Sj6O2jr0TOKv16f+nmSxnWLsv4a60\nY5R6n8cR1K6gb6NecHkw9SIQ9PsO/C/wEmrXwce1z79sBp8HOKWUcnLndW5n3ibAXtz+GL2nzR8c\no3dSWxE+RR397yEs73K6Kv8fk5noez5tWUd1bKVV4T0QWlBKKb9Pvcn5QOqVqBM7s58BfBQ4Psmj\nSyndG7Avp3YL+NtJFv37zvvjqP3HH9U+dxr1xL5JksFQmR/p5O+77IuofXmHbTpB2oy0+yseC5xQ\nphh5pJRyOLWlZH1qQPQu4BtJtijTjwIEk7duTGSi7dqU2pI0cAM1+Ooa/oE1E4MfY3djxfsJ7jY0\nv7eV2GdXUvfT3SaYd7eVKQN1+Na3U++zee80eWd9H4xIn2Pf3ZZhdwNOmeHyKKWcCjyjXcXdkXpf\nxeeSPKCUcsYkZf0W8LgkDyqlnDJJnoHLgXOp55CJnDfN54fLW6jnm4+0iyaPp34HPksNKqCef1bY\n9iQTbftvgL1Sbw54APBy4INJziulfH0m5ep4ArWr2ffb9DbU/frcUsptrWBJntJnYakDT+xO7Xp1\nYCf9r1eyfBO5nNqS8K5J5g/O2XsAnyilvK1TjvVnsJ7r22fWKqXc2Emf7Bw30fm1V1lHdGyllWYL\nhOZNhkZZ6diu/R0eoelC6g+81ahDW3Y//w3qFaMNhq5KDV7dAOLbwBbUG+KOL9Wl1HsV3kKtLI9b\niWX/CNgyyW1dGNrVusl+aPTSKox3U69Uvb/PZ0op15RSjqT+MNmM5RXaDdSbNGfDM7PiqDM7U/fr\njzp5zqe28nQ9aYJl9S3Xd9vf4Rstn9P+Ht9jGROaYp8N57uW+sP277PiqDP3pN6sO+MylFJOpH4v\nX59JHoaVZDCM6yj2wY3M3vdioM+xP5PaarXCtiT5G+pV/uNnuLzblFJubt0J30Q9Z9xnsrzAx6j3\nYH2gdVFbQeqoS49tk9+gtlhdM8n54A9TrGdKpZQrSymfpXZ77G7rTLe9tEDqVS1p+LO9pD5E7t3U\niyOfacmDLlY3dfKtyfLvX9dE36u1qefY4YEW9l6ZMk7iG9Qb0X8+yTEatAKtO0E59plgeZOdn85v\nf2/bv60b5EyG/O1bVmD2jq20qmyB0Hw6I8m3qP0/zwXuRB1V4iXA50opvx3+QCnloiS7UH9sHdda\nIn5fSjk+yaepV5LfR225uJV689puwGvL8lGevkcdBeUxLG82hxo0vBz4bemMfz+DZR9KHYHki0le\nT+3i9JK2XX2t1QlA1mX5g+QeRr0ZcdInGSc5gNoCcBz1qtUW1FGATi31eQpQb3x+aZJ/oF69vrqU\ncuYMytd1R+DLST5CHX3lndQ+6J/o5PkM8MYkbwBOoLbiPHt4QX3LVUo5ox2L/dsV5h9S982bgE+X\nUk4f/sxUeu6zibyJ2rf9yNQhQtenBp9/YvoWhMnsSb0SflKS/2L5g+S2o452tCZ1tLJZ3QfNL4An\nJfkGtYXl90NB98qY9tiXUm5J8mbq1fdPUbuSbE5tjTmbFR/cNe3ykjyZOsLNl6nnlPWox/NqVgxs\nV1BKuaJ1czoC+Enb/4MHyT2E+n98OPX4HEb9kXls6vMhfkZtHdiG+hDIvyszeF5Cko92yncpdXCJ\n57L8HqvBth+c5P3UEZ0ewNAP7tbt7kBqy8U51B/pe1NHUOrzILfN27lnNWrXsZ2oA0MEeEop5c8t\n3y+pP5zfnuQW6g/wyR6wN+H3KskJwKuTXEQN3J7H7HZ9fDP1PP3dJB+gtgptRP2xfa9SyuCp0t+g\njgR4OnWfPZ2Jf/xPdn76OvV//n+S7EcNjv4N6D1yWJ+yzsKxlWZfWQB3cvsazxe1Uj6CWhldT73H\n4KfUE/BanXx700Zh6qRtQr1X4ixg85a2GnXo1Z+15f2pvX83tfWgu+4f0xlpqaUNRmg6ZIKy9lo2\n9R6Oo4DrqCNrHEht6bhtJKEp9schLB9R5Fbqj4pfUkfp2GmC/Ht3l0u9Ink09WrhDdR+3R9nxZFx\n7tbKdzWd0XQm2sdD5TqvM71Vy/tS4H1tO6+j/qDeeuizd2j74KK2zs9Sf5DdNnJOz3Jt1cm7FrXv\n9fnUHy/nt+k1JyjjC4bKs0tL36XvPpvieO1K/dH35/Z9+Apw76E8vUZh6uRfnzqM5E+p/w83UK/S\nH0j9MTHr+6Cl7UxtVbmeFUf2mezY91lmr2Pf8u5J/X+6gdql45PAZjP9LlED7s9Sg4frqd/No4CH\n9tz/96SOijS4ufca6k3O+wJ3GirL/sCvWr4rWr79aSNzdfbJY6f5v11GbWm5tC3rXGpLY3d9q1F/\naJ5P/V87mhqwdI/VJtSLGGe1PFcA3wGe0GO7u6MZ3UT9Uf996sheG0+Qf/s2/zrqwAkHUJ+lMfy/\nOtn3aivqj++r23Z/gPq/uMJ3aJKy7t/yrTFNvi2oLUsXUgPxi6gjG+3ZyXNXanB2ZXsdRr0fo9f5\nqc17eDv217V9vyc9/2/6lnVVjq0vX6N6DYaRkyRJkqRpeQ+EJEmSpN4MICRJkiT1ZgAhSZIkqTcD\nCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQkSZKk3gwgNKEkhyQ5chaWs3+S\nM2ajTNOsZ6skJcmOo17XuEuyd5JrRrTs45N8oDN9XpLXjGhdI9sOaRzMZT0xW+vS6Iyyvh+uC1p9\n/8wRrWtOfrcsdgYQi0A7ce4/x6t9BbBnpwwr/LBbgH4HbAac2vcDSXZJct40ec5rJ6ru64+rWNbh\ndcz7vm37YrB9tya5KslpSQ5MsvVQ9s8C9+q53JkGdk8HXjeTsvcsx0SVTe/tkBY664nZ0y4uHD9N\nnuF6oSTpXf/0LMfILqDMoAx7d7bvliR/THJykrcn2WQo+38Aj+y53EGdc9eeRXkw8MGZlL1HGSar\nn3pvxzhbY74LoIWplPKn+S7DTJRSbgEuHtHiDwA+1Jm+dUTrWWVJ1iyl3LQKi/gr4ApgfeABwCuB\n05M8qZTyHYBSyp+BP69yYTuSrFVKubGUcsVsLncqo9gOaZwstnpiBF4IdFtFVuXcOzJJVgPS6smV\ncR2wDRDgTtQf868FXpjkkaWUXwKUUq4BZrVVt1M3XDaby53KKLZjKbIFYhFKslaSdyQ5P8kNSX6T\n5F/avNWTfDzJuUn+nOTsJP/WTiCDzx+S5Mgkb0xySZJrkvxvknWG8wzeU6Pxl3WuRGzVZ109t2e9\nJJ9o5bgkyeta+Q7p5NkzyUlJrk5yaZLPJ9m8M3+FKwmdqxuPSfLjJNe1qyY7rMQuv7qUcnHndWln\nvRsk+Wgr09VJvtO9mpHkLkk+neSCto9+nmSfzvzJ9u3trs5MsY27JTkxyY3AE9q8pyQ5Jcn17fi8\nPclaPbb10raN55RSvgDsAvwUODjJ6m3ZK3T9SbJlkq8kuaLt518l2aPNPrf9PamV9fjBdrdj/Nok\nFwAXtPSJrmCun+RT7ftxcYauyGWC1oV0rtxleSvT51ve8ybajpb24iTnJLmx/X3hBOt6Ufv+Xdv+\n9/ZEWmCyxOqJCbZv7ST/2cp2fZITkjy8M3/NJAcl+X3b/t8l+ffO/KentrL+uZ27vpNk0xkW449D\ndcPlneVvnuQzSa5sr68l2bYzf5t23ry4nUt+kuTJnfnHA/cE3jPYny19ovPWCvXFIE+rG84AbgTu\n0+btk+QXbZ+dleRfexyL0rbvolLKmaWUTwEPA/4IfLhTjhW6/iT56yTHprZoX5PkZ0kelWQr4LiW\n7bJW9kMG253kQ0n+I8llwA9a+kStMXdr+/W69j3vtoZN2LqQFeuLyeqn4e1YLcmb2nfohiSnJ9l9\ngnU9I8kxrTy/SPK4afbromYAsTgdCuwFvIp6Ung+9R8Z6jG9EHhWm/cG4PXAPkPLeCT1CvNjgGcA\njwfeNcn6XgH8CPhfajehzahdhvquazrvbeV5GvDoVq6/HcqzFrBfm/dk4K7Ap3ss+53AvsAOwOXA\nYUkyw/JNqC3na8DmrUwPBL4LfDvJZi3bHYCftPl/BRwIfCTJY9r8yfbtTLwLeCOwHfDjJE8ADgM+\n0Nb5POCZwDtmuo3titX7qV19HjhJtg8C6wKPaut7Jcu/jw9pf3elbtvTO597JHD/Nu8xTO5VwC+p\nx3A/4B1Jnj5F/mEPbn9f2Mrw4IkyJXkadZ/9J3A/6rH6YJKnDGV9M/AV6nfxs9Tg6h4zKI80F5Za\nPTHs3cA/UM9vDwROB77ROff+C7VO2QPYtuU9EyDJ3YDPUPfRfYBHAJ9cxfLcJsm61B/I11P34cOA\ni4BvtXlQW3m/DjyOuo+/AHwxyXZt/tOpF1YOYPn+nIk7AG8CXgzcFzg/9YLIO6jnsPsAr6a2JLx0\nptvYrtJ/GHhEko0nyfZ/1O1+CLA9sD91n/yO+n2CWmdsRv3+DOxJbe34W+p3eDJvAY5oy/4o8Inh\ngGEaU9VPXa8A/h91X/018CXqsdp+KN/bgYOox/Mk4DNJ1p9BeRaXUoqvRfSinggLsOsMPvPvwLc6\n04dQK5L1O2l7AjcA63XyHNmZfzzwgZVY1/7AGVPkX596dWSPTtp6wJXAIVN8bru2H7Zo01u16R3b\n9C5t+gmdz+zc/UzPfXde2y/XdF6vb/Me3abXGfrMqcC/TbHMzwAfm2rfdsp/107aZNv4jKHPfhd4\n01Da37WyZpIy3W59E+zrZ7XpvYFrOvNPA/abZLkrlHnoO3gZsPZQ+gr7ou3/Y4byfAz4fme6AM+c\n4Li9Zpo8w9vxA+DgCco5vK53dqbXoDbv79n3O+XL16hfLLF6Ynhd1DriRmCvzvzVgV8Db2vTBwHH\nTnTOo16MKMA9V2EfF2oXyG7d8Jw273nA2d11t/JdPjiPTrLME4A3dqZXOI+1tBXOWy1tFzrn75an\nAA8ayvdb4LlDaa8EfjFFmW63vs68Xdt6HjLRcQSuApZN8tkVyjz0HTptgvwr7Iv22f8ZyvMt4FPt\n/VZMXPfcVhdMkWd4Oy4E3jxBOYfX9eLO/M1b2sNX9ju20F/eA7H4PJDaB/+4yTIkeQnwAmrz5zrA\nmsD5Q9lOK/UKwsCPqFf5t6H+IOyl57oGef+WesVl4MXAGe0zJw4SSynXZmgEhNSuR/tRrzTcmXp1\nAuAetO4vk+huy+/b302m+cyw9wEf70wP+uk/iHrl/bKhRo07UPcjqd1+9qVe/docWJu6n4+fwfqn\nc/LQ9IOAhyR5bSdtNerxuRv1itBMDDauTDL/QODDSXalVthfKqWc0mO5Z5RSbuiR70cTTM+kBaKv\n+wAHD6V9H3jqUNpt36lSys2tmX34ZkJpPi2peqKUcthQtm3aMn4wSCil3JLkR9Sr7VADjmOAs5J8\nEzgK+Hop5VbgZ9Qfm2e0ed8CDi8z72f//4BvdKYvaX8fBGwNXD1UN6zL8rphPWqd9mTq1e81qXVH\n7/06jZvpDCrSWgm2pLaAd+/pW4Pl5/iZmq5ueB/wsSTLqHXDF0opv+qx3D71B0xcNzyp52d7SXIn\n4O50vmvN94HdhtIm+72xJBlALDFJ/oHaBeM1wA+pVwBeRm3Kne91nUwNAAYuoccoOO1EezT1JP9c\n4FJqF6bvUSuzqXRvahuc5Gbade/yUso5E6SvRt2G4e5WUPcF1H3zamoT6OnUq1TvYPqTyuBG7e6J\nfc1J8l47QbneAnx+grwrcyPaoEL+zUQzSykfT3I09WT6WOCHSd5ZStl/muUOl3tlFW5fAU62r1Z2\n+V3DN0oW7A6qRWQR1hMzUS8zl/KT1tf+CdQuWIcCP0vyuBZsPB7Yidot6/nAO1NvCP7ZDNZ18RR1\nw6nU7lPDBheg/oN6Bf811NaK64BPMH2ddiv9znc3lBVvmh6co15CPQ6z4b7U/X3eRDNLKfsnOQx4\nIvU47JfkJaWU4Qs1w2ajbrhdHZpkNusFmKJuKKWUFjwu2brBAGLxOZX6hXwUK175GHg48ONSSncs\n/W0myPfXSdYrpQz+UXeiNgn/epL13khtgl2ZdQG3jXqzwsk2ya+p/3QPpv1AbX1E79cpy3bUgOH1\npZRzW55RXIGeqZ8AmwK3llIm/HFN3UdfLaV8Em67b+IvWd4XGSbet4Mf+pt13g/3t5yqXNtNUrHN\nSGtBeSX1WEw6RGEp5QJqH9SPtpaPV1CbgW9sWYa3byZ2mmD6l53py+j0D069EXK4v/BNPcrwS2o3\nt25r08OBX8yksNICsKTqiQn8uq1r50FZ2rnqYdR+94NlXQ0cDhzebtI9AfgL4KxS+5n8CPhRkgOA\nn1NbimcSQEzmJ8CzgT+UUiYb9vvhwCdKHayCJIOW67M6eSarG9ZNcqdSyuBC1bR1QynlkiS/B7Yp\npXyi/6ZMrPXtfwnwnalabkopZ1MDpINay8cLqC29s1U3HDw0PagbunXowPB+mrYMpZSr2n7bmdqK\nMjD2dYMBxCJTSjkryeeozYKvoJ6otgC2aj9SzwL2TvJE6kl4D+pNXFcOLWoN6s2fB1Cb5/6d2p9w\nssj/PGq3mK2oV9GvmMG6ptqea5IcDLwryR+o3WveSK38BtH9b6n9bl+e5L+pXU3e2ncdI/QtarPm\nV5L8G/ArahehXan9e79H3Uf/kDo6yB+Af6Y2bf+0s5zzuP2+PYd6o9n+Sfal9rF8Y89yHQAcmeR8\n4HPUpuz7Ufup/ts0n90kyRrUe1PuD/wrtTvEbmWSIQCTHEjtcnAWdYi/XVl+Yr2U2k/4CamjH11f\nZj70405JXkf9IbAL9aa653Tmf5s68ssPgVuoLTzXDy3jPOAxSb5DvTI30Xf0PdSRmk4Bvtm24zmM\npruUNDJLrZ6YYPuubT9GB/XGudRz1aa0ZwUkeRW1PjmVegHhH6mtHxck2YnaWno0tYXjgdTuPbP1\ng/AwasvCV5K8mVqHbQnsDny4/ag+C3hakq+08u1H7cLUdR7wt0k+RT1v/QH4MfUK/TuTvJ96w27f\nm6D3A/4r9VlGR1FbLnYANi+lvHOKz6XdeA6wAcuHcd2A23fxHHxgHWory+fbdmxKCyZblvOpdfyT\nknwV+PNQd7k+np7kJGqX4GdSW5oeCjUQTXIC8Np2oXID6qAqXX3rp/cAByQ5m9q9ak9qz4OVGdVx\nyViyTStL3F7UqywHUX+0HkL95wD4CPVH4/9RRwHYijrK0bDvUK+4HEcdUeDbwFQ/Lv+DGq3/ghrZ\n32MG65rOa6jdkY5o5TmN2ox9PUC7urGMeiPwL6gnwVetxHpmVbuCtRt13/0PdYSPzwH3Znn/x7dR\n7+/4OvXm5muplUvX7fZtqc9y2IPaxetn1C5Jr+9ZrqOp/UAf1dZ9IvU+jN/2+PjPqZXuT6mByE+B\n+5dSvjvodBlsAAAgAElEQVTFZ1YD/quV/xhqhbysleVm6mgoL6Duk6/02YYh76MGMz+l7s83l1IO\n78x/NbX16nhqkPExasXAUJ5HUYOynzKBUsqXqQHev7ZteQXw0lLKV1eizNJ8W2r1xLDXUkdB+19q\nkHB/6k3jg3u8rqbeo3AiNYDaHnhiKeU64E/UK8pHUq+Ovxd4a6nDk66yto5HUM9Ln6fu/0OBjVge\nOL2Kep76HrV+OKG973ozNfD4Ne2KeqnPynkOdfSm04EXUUdb6lOuj1Fv8H4utV75Xvv8udN8dF1q\nvfB76v58FfBV4H6lPQNiArdQt/cQat34JWqLz6taWS6k1uVvp9YZK/MAwv2pozmdBvwTsE8p5aTO\n/Oe1vydRv4crXISbQf10EDWIeDf1vs2nUQcvmY3WqkUr9TeQxklryr1rKeXJ0+WdD0nWpl6deE8p\nZTYqGknSDCz0ekLS/LILk+ZdkgdSuyWdCNyRemXpjtSrS5IkSVpA5q0LU5LDkpyZ5IwkBw/ujk91\nUOpTYE9L58nBSZalPsXy7DYs2CD9QalPBjynfXZWHhSmOfUqateSb1P7Sj6i3ZgracxYP0jSwjay\nLkxJNprkRsXB/N1YPtbz/wHfLaV8qKX/M7Vv+UOBA0spD01yZ2q/+B2pN96cQn1IypVJTqT2Y/sx\n9cagg0opX0eStOBYP0jS4jbKFoiT21WkR090xaeUclRpqF1XtmizdqcObVZKKScAG6Y+mv4J1CfS\nXtEqnmOAXdu8O5VSTmjL+gT1ZltJ0sJk/SBJi9go74H4S+rDQ14O/HeSTwKHlFJ+383UmqafSx3x\nBOrTen/XyXJBS5sq/YIJ0m8nyYuoIw6w3nrrPWi77bab8UadcvnlM8r/oLvcZcbrkKRROuWUU/5Q\nStl4HouwoOqH2agbwPpB0uLXt34YWQDRxow/kjoe/cbU8Xd/m+RvSikndrJ+kNo8PTx82SjK9FHq\nw67Ycccdy8knnzzjZeTQQ2eU/+Rly6bPJElzqD0jZN4stPphNuoGsH6QtPj1rR9GehN1kg2SvJg6\nvv+21DF5T+vM3w/YmBXH9L+QOu7xwBYtbar0LSZIlyQtUNYPkrR4jSyAaE9O/An1qbt7lVIeWUr5\nRCnl+jb/BdR+q88updza+egRwF5ttI2dgD+1B8McDTw+yUZJNgIeDxzd5l2VZKfWl3YvVu5hVZKk\nOWD9IEmL2yjvgfgcsHd70t9EPkx9WNiP2j10XyylHEAdJWM36iPvrwP2gfr0xSRvpT5REOCA9kRG\nqI9xPwRYhzpyhyNsSNLCZf0gSYvYKO+BOGKa+ROuu42U8bJJ5h0MHDxB+snA/VaimJKkOWb9IEmL\n27w9SE6SJEnS4mMAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGE\nJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSb\nAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS\n1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAk\nSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOA\nkCRJktSbAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6\nM4CQJEmS1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJ\nknozgJAkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCS\nJEmSejOAkCRJktTbvAUQSQ5OcmmSMzpp+ye5MMmp7bVbZ97rkpyT5MwkT+ik79rSzkmy71xvhyRp\ndlk/SNLCNp8tEIcAu06Q/v5SyvbtdRRAkvsCewB/1T7zwSSrJ1kd+G/gicB9gWe3vJKkxesQrB8k\nacFaY75WXEr5bpKtembfHfhMKeUG4Nwk5wAPafPOKaX8BiDJZ1reX8xycSVJc8T6QZIWtnkLIKbw\n8iR7AScDry6lXAlsDpzQyXNBSwP43VD6Q+eklD3l0EN75y3Llo2wJJK06C2p+kGSFquFdhP1h4Bt\ngO2Bi4D3zubCk7woyclJTr7ssstmc9GSpNEaWf1g3SBJM7OgAohSyiWllFtKKbcC/8PyZugLgS07\nWbdoaZOlT7b8j5ZSdiyl7LjxxhvPbuElSSMzyvrBukGSZmZBBRBJNutMPg0YjMBxBLBHkrWTbA1s\nC5wInARsm2TrJGtRb6Q7Yi7LLEkaPesHSVo45u0eiCSfBnYB7prkAmA/YJck2wMFOA94MUAp5edJ\nPke9+e1m4GWllFvacl4OHA2sDhxcSvn5HG+KJGkWWT9I0sI2n6MwPXuC5I9Pkf/twNsnSD8KOGoW\niyZJmkfWD5K0sC2oLkySJEmSFjYDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSb\nAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS\n1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknqbNoBI\nsnOS9dr7PZO8L8k9R180SdJCZv0gSeOpTwvEh4DrkjwAeDXwa+ATIy2VJGkxsH6QpDHUJ4C4uZRS\ngN2BD5RS/hu442iLJUlaBKwfJGkMrdEjz9VJXgfsCTwiyWrAmqMtliRpEbB+kKQx1KcF4h+AG4Dn\nl1IuBrYA3jPSUkmSFgPrB0kaQ9O2QLRK4X2d6d9iH1dJGnvWD5I0niYNIJJcDZTJ5pdS7jSSEkmS\nFjTrB0kab5MGEKWUOwIkeStwEfBJIMBzgM3mpHSSpAXH+kGSxlufeyCeWkr5YCnl6lLKVaWUD1FH\n3JAkjTfrB0kaQ30CiGuTPCfJ6klWS/Ic4NpRF0yStOBZP0jSGOoTQPwj8Czgkvb6+5YmSRpv1g+S\nNIamHIUpyerA00opNklLkm5j/SBJ42vKFohSyi3As+eoLJKkRcL6QZLGV58nUf8gyQeAz9Lp21pK\n+cnISiVJWgysHyRpDPUJILZvfw/opBXg0bNfHEnSImL9IEljqM+TqB81FwWRJC0u1g+SNJ6mHYUp\nyQZJ3pfk5PZ6b5IN5qJwkqSFy/pBksZTn2FcDwaupg7V9yzgKuB/R1koSdKiYP0gSWOozz0Q25RS\nntGZfkuSU0dVIEnSomH9IEljqE8LxJ+TPHwwkWRn4M+jK5IkaZGwfpCkMdSnBeKfgEM7/VqvBPYe\nWYkkSYuF9YMkjaE+ozCdCjwgyZ3a9FUjL5UkacGzfpCk8dRnFKZ3JNmwlHJVKeWqJBsledtcFE6S\ntHBZP0jSeOpzD8QTSyl/HEyUUq4EdhtdkSRJi4T1gySNoT4BxOpJ1h5MJFkHWHuK/JKk8WD9IElj\nqM9N1IcBxyYZjO29D3Do6IokSVokrB8kaQz1uYn6XUl+Bjy2Jb21lHL0aIslSVrorB8kaTz1aYEA\n+CVwcynlW0nWTXLHUsrVoyyYJGlRsH6QpDHTZxSmFwKHAx9pSZsDXx5loSRJC5/1gySNpz43Ub8M\n2Bm4CqCUcjawySgLJUlaFKwfJGkM9Qkgbiil3DiYSLIGUEZXJEnSImH9IEljqE8A8Z0krwfWSfI4\n4PPAV0dbLEnSImD9IEljqE8AsS9wGXA68GLgKOCNoyyUJGlRsH6QpDHUZxjXW4H/aS8AkuwM/GCE\n5ZIkLXDWD5I0niYNIJKsDjyLOqrGN0opZyR5MvB6YB3ggXNTREnSQmL9IEnjbaoWiI8DWwInAgcl\n+T2wI7BvKcVh+iRpfFk/SNIYmyqA2BG4fynl1iR3AC4GtimlXD43RZMkLVDWD5I0xqa6ifrG1r+V\nUsr1wG+sHCRJWD9I0libqgViuySntfcBtmnTAUop5f4jL50kaSGyfpCkMTZVAHGfOSuFJGkxsX6Q\npDE2aQBRSjl/LgsiSVocrB8kabz1eZCcJEmSJAEGEJIkSZJmYNIAIsmx7e+7RrXyJAcnuTTJGZ20\nOyc5JsnZ7e9GLT1JDkpyTpLTkuzQ+cyylv/sJMtGVV5J0ujrB+sGSVrYpmqB2CzJ3wBPTfLAJDt0\nX7O0/kOAXYfS9gWOLaVsCxzbpgGeCGzbXi8CPgS1UgH2Ax4KPATYb1CxSJJGYtT1wyFYN0jSgjXV\nKExvBt4EbAG8b2heAR69qisvpXw3yVZDybsDu7T3hwLHA69t6Z8opRTghCQbJtms5T2mlHIFQJJj\nqBXPp1e1fJKkCY20frBukKSFbapRmA4HDk/yplLKW+ewTJuWUi5q7y8GNm3vNwd+18l3QUubLF2S\nNALzVD9YN0jSAjFVCwQApZS3Jnkq8IiWdHwp5cjRFuu2dZckZbaWl+RF1CZu7nGPe8zWYiVpLM1X\n/WDdIEnza9pRmJK8E3gF8Iv2ekWSd4ywTJe05mfa30tb+oXAlp18W7S0ydJvp5Ty0VLKjqWUHTfe\neONZL7gkjZM5rh+sGyRpgegzjOuTgMeVUg4upRxM7UP65BGW6QhgMFrGMuArnfS92ogbOwF/as3Z\nRwOPT7JRu0Hu8S1NkjRac1k/WDdI0gIxbRemZkPgivZ+g9laeZJPU290u2uSC6gjZvw78LkkzwfO\nB57Vsh8F7AacA1wH7ANQSrkiyVuBk1q+AwY3zUmSRm7W6wfrBkla2PoEEO8EfprkOCDUvq77Tv2R\nfkopz55k1mMmyFuAl02ynIOBg2ejTJKk3kZSP1g3SNLC1ucm6k8nOR54cEt6bSnl4pGWSpK04Fk/\nSNJ46tWFqfUnPWLEZZEkLTLWD5I0fvrcRC1JkiRJgAGEJEmSpBmYMoBIsnqSX81VYSRJi4P1gySN\nrykDiFLKLcCZSXw0pyTpNtYPkjS++txEvRHw8yQnAtcOEkspTx1ZqSRJi4H1gySNoT4BxJtGXgpJ\n0mJk/SBJY6jPcyC+k+SewLallG8lWRdYffRFkyQtZNYPkjSeph2FKckLgcOBj7SkzYEvj7JQkqSF\nz/pBksZTn2FcXwbsDFwFUEo5G9hklIWSJC0K1g+SNIb6BBA3lFJuHEwkWQMooyuSJGmRsH6QpDHU\nJ4D4TpLXA+skeRzweeCroy2WJGkRsH6QpDHUJ4DYF7gMOB14MXAU8MZRFkqStChYP0jSGOozCtOt\nSQ4Ffkxtmj6zlGITtSSNOesHSRpP0wYQSZ4EfBj4NRBg6yQvLqV8fdSFkyQtXNYPkjSe+jxI7r3A\no0op5wAk2Qb4GmAFIUnjzfpBksZQn3sgrh5UDs1vgKtHVB5J0uJh/SBJY2jSFogkT29vT05yFPA5\nah/XvwdOmoOySZIWIOsHSRpvU3Vhekrn/SXAI9v7y4B1RlYiSdJCZ/0gSWNs0gCilLLPXBZEkrQ4\nWD9I0njrMwrT1sA/A1t185dSnjq6YkmSFjrrB0kaT31GYfoy8HHq00VvHW1xJEmLiPWDJI2hPgHE\n9aWUg0ZeEknSYmP9IEljqE8AcWCS/YBvAjcMEkspPxlZqSRJi4H1gySNoT4BxF8DzwUezfIm6tKm\nJUnjy/pBksZQnwDi74F7lVJuHHVhJEmLivWDJI2hPk+iPgPYcNQFkSQtOtYPkjSG+rRAbAj8KslJ\nrNjH1WH6JGm8WT9I0hjqE0DsN/JSSJIWI+sHSRpD0wYQpZTvzEVBJEmLi/WDJI2nPk+ivpo6qgbA\nWsCawLWllDuNsmCSpIXN+kGSxlOfFog7Dt4nCbA7sNMoCyVJWvisHyRpPPUZhek2pfoy8IQRlUeS\ntAhZP0jS+OjThenpncnVgB2B60dWIknSomD9IEnjqc8oTE/pvL8ZOI/aTC1JGm/WD5I0hvrcA7HP\nXBREkrS4WD9I0niaNIBI8uYpPldKKW8dQXkkSQuc9YMkjbepWiCunSBtPeD5wF0AKwhJGk/WD5I0\nxiYNIEop7x28T3JH4BXAPsBngPdO9jlJ0tJm/SBJ423KeyCS3Bl4FfAc4FBgh1LKlXNRMEnSwmX9\nIEnja6p7IN4DPB34KPDXpZRr5qxUkqQFy/pBksbbVC0QrwZuAN4IvKE+ZBSAUG+Su9OIyyZJWpis\nHzQWcuihvfOWZctGWBJpYZnqHogZPaVakjQerB8kabxZCUiSJEnqzQBCkiRJUm8GEJIkSZJ6m3IY\nVy1sM7m5C7zBS5IkSavOFghJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGEJEmS\npN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSbAYQk\nSZKk3gwgJEmSJPVmACFJkiSptwUbQCQ5L8npSU5NcnJLu3OSY5Kc3f5u1NKT5KAk5yQ5LckO81t6\nSdIoWDdI0vxbsAFE86hSyvallB3b9L7AsaWUbYFj2zTAE4Ft2+tFwIfmvKSSpLli3SBJ82ihBxDD\ndgcObe8PBf6uk/6JUp0AbJhks/kooCRpzlk3SNIcWsgBRAG+meSUJC9qaZuWUi5q7y8GNm3vNwd+\n1/nsBS1tBUlelOTkJCdfdtlloyq3JGl0rBskaZ6tMd8FmMLDSykXJtkEOCbJr7ozSyklSZnJAksp\nHwU+CrDjjjvO6LOSpAXBukGS5tmCbYEopVzY/l4KfAl4CHDJoPm5/b20Zb8Q2LLz8S1amiRpCbFu\nkKT5tyADiCTrJbnj4D3weOAM4AhgWcu2DPhKe38EsFcbcWMn4E+d5mxJ0hJg3SBJC8NC7cK0KfCl\nJFDL+H+llG8kOQn4XJLnA+cDz2r5jwJ2A84BrgP2mfsiS5JGzLpBkhaABRlAlFJ+AzxggvTLgcdM\nkF6Al81B0SRJ88S6QZIWhgXZhUmSJEnSwmQAIUmSJKm3BdmFSZIkabbl0EOnzyRpWrZASJIkSerN\nFghJkqRVNNPWjbJs2fSZpAXKFghJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAkSZLUmwGE\nJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9GUBIkiRJ6s0AQpIkSVJvBhCSJEmSejOAkCRJktSb\nAYQkSZKk3gwgJEmSJPVmACFJkiSpNwMISZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS\n1JsBhCRJkqTeDCAkSZIk9WYAIUmSJKk3AwhJkiRJvRlASJIkSerNAEKSJElSbwYQkiRJknozgJAk\nSZLU2xrzXQBJUpVDD51R/rJs2YhKIknS5GyBkCRJktSbAYQkSZKk3gwgJEmSJPXmPRALyEz7P0uS\nJElzzRYISZIkSb0ZQEiSJEnqzQBCkiRJUm/eAyFJkhYl7x2U5octEJIkSZJ6M4CQJEmS1JsBhCRJ\nkqTeDCAkSZIk9WYAIUmSJKk3R2GSJEla4GYy4lRZtmyEJZFsgZAkSZI0A7ZASJIkzTGfYaHFzBYI\nSZIkSb0ZQEiSJEnqzQBCkiRJUm8GEJIkSZJ6M4CQJEmS1JujMGlWzHQ0CceoliRJWpxsgZAkSZLU\nmwGEJEmSpN7swiRJkrSE2K1Yo2YAoQn5hExJkiRNxC5MkiRJknozgJAkSZLU25LpwpRkV+BAYHXg\nY6WUf5/nIkmSFgDrh8XFLrTSwrckAogkqwP/DTwOuAA4KckRpZRfzG/JJEnzaVzrB2+ilTRKSyKA\nAB4CnFNK+Q1Aks8AuwNLuoKQJE1rwdYPM/mRv5h/4NuisPSMy3dXk1sqAcTmwO860xcAD52nsmiW\njfpKmidCaUmzfphlBgSaicXcGraYyz5qKaXMdxlWWZJnAruWUl7Qpp8LPLSU8vKhfC8CXtQm7w2c\nuRKruyvwh1Uo7mIxLtsJ47OtbufSs7Lbes9SysazXZiFqE/9MEt1A4zXd2867ovl3BfLuS+WW6j7\nolf9sFRaIC4EtuxMb9HSVlBK+Sjw0VVZUZKTSyk7rsoyFoNx2U4Yn211O5eecdrWVTBt/TAbdQN4\nPLrcF8u5L5ZzXyy32PfFUhnG9SRg2yRbJ1kL2AM4Yp7LJEmaf9YPkjTLlkQLRCnl5iQvB46mDtN3\ncCnl5/NcLEnSPLN+kKTZtyQCCIBSylHAUXOwqlVu5l4kxmU7YXy21e1cesZpW1ea9cO8cF8s575Y\nzn2x3KLeF0viJmpJkiRJc2Op3AMhSZIkaQ4YQMxAkl2TnJnknCT7znd5+kiyZZLjkvwiyc+TvKKl\n3znJMUnObn83aulJclDbxtOS7NBZ1rKW/+wkyzrpD0pyevvMQUky91t6W1lWT/LTJEe26a2T/LiV\n7bPtJkqSrN2mz2nzt+os43Ut/cwkT+ikL4jjn2TDJIcn+VWSXyZ52FI8nkn+tX1nz0jy6SR3WCrH\nM8nBSS5NckYnbeTHcLJ1aNUtlPPDKI36e7tYZA7q1cWinZdPTPKzti/e0tJn7Vy92GSEv0MWlFKK\nrx4v6s13vwbuBawF/Ay473yXq0e5NwN2aO/vCJwF3Bd4N7BvS98XeFd7vxvwdSDATsCPW/qdgd+0\nvxu19xu1eSe2vGmffeI8bu+rgP8DjmzTnwP2aO8/DPxTe/9S4MPt/R7AZ9v7+7ZjuzawdTvmqy+k\n4w8cCrygvV8L2HCpHU/qw7/OBdbpHMe9l8rxBB4B7ACc0Ukb+TGcbB2+Vvl4Lpjzw4i3c6Tf28Xy\nYg7q1cXyatu0fnu/JvDjto2zcq6e7+1byX0ykt8h871dt9vO+S7AYnkBDwOO7ky/DnjdfJdrJbbj\nK8DjqA9K2qylbQac2d5/BHh2J/+Zbf6zgY900j/S0jYDftVJXyHfHG/bFsCxwKOBI9uJ7Q/AGsPH\nkDoiy8Pa+zVavgwf10G+hXL8gQ2oP6wzlL6kjifLnx5853Z8jgSesJSOJ7AVK/4QG/kxnGwdvlb5\nWM7792kOt3Uk39v53q5V3CezWq/O9/aswn5YF/gJ9Unvs3Kunu9tWol9MLLfIfO9bcMvuzD1N/hB\nM3BBS1s0WvPYA6lXCDYtpVzUZl0MbNreT7adU6VfMEH6fPhP4N+AW9v0XYA/llJubtPdst22PW3+\nn1r+mW7/XNsauAz439ZE+rEk67HEjmcp5ULgP4DfAhdRj88pLL3j2TUXx3CydWjVLMTv01yZre/t\nojSienVRaV12TgUuBY6hXjGfrXP1YjPK3yELigHEmEiyPvAF4JWllKu680oNcRf1cFxJngxcWko5\nZb7LMmJrULsQfKiU8kDgWmpT+W2WyPHcCNidGjDdHVgP2HVeCzWH5uIYLoXviRaWcftOLfV6ta9S\nyi2llO2pV98fAmw3z0WaF2P0OwQwgJiJC4EtO9NbtLQFL8ma1JPcYaWUL7bkS5Js1uZvRr1yAJNv\n51TpW0yQPtd2Bp6a5DzgM9TmwwOBDZMMnnfSLdtt29PmbwBczsy3f65dAFxQSvlxmz6cGlAsteP5\nWODcUsplpZSbgC9Sj/FSO55dc3EMJ1uHVs1C/D7Nldn63i4qI65XF6VSyh+B46jddGbrXL2YjPp3\nyIJiANHfScC27W76tag3vBwxz2WaVpIAHwd+WUp5X2fWEcCy9n4ZtQ/nIH2vNmrETsCfWpPs0cDj\nk2zUrg4/ntqP7yLgqiQ7tXXt1VnWnCmlvK6UskUpZSvqsfl2KeU51JPZM1u24e0cbP8zW/7S0vdo\noyNsDWxLvSF1QRz/UsrFwO+S3LslPQb4BUvseFK7Lu2UZN1WjsF2LqnjOWQujuFk69CqWYjfp7ky\nK9/buS70qhh1vTonGzFLkmycZMP2fh3qvSC/ZPbO1YvGHPwOWVjm+yaMxfSijqRwFrV/3xvmuzw9\ny/xwajPqacCp7bUbtZ/dscDZwLeAO7f8Af67bePpwI6dZT0POKe99umk7wic0T7zAYZu8J2Hbd6F\n5aMf3Iv6j3cO8Hlg7ZZ+hzZ9Tpt/r87n39C25Uw6IxAtlOMPbA+c3I7pl6mjdyy54wm8BfhVK8sn\nqSNSLInjCXyaem/HTdRWpefPxTGcbB2+ZuWYLojzw4i3caTf28XyYg7q1cXyAu4P/LTtizOAN7f0\nWTtXL8YXI/odspBePolakiRJUm92YZIkSZLUmwGEJEmSpN4MICRJkiT1ZgAhSZIkqTcDCEmSJEm9\nGUBIqyDJcUmeMJT2yiQfmuIz14y+ZJKk+WT9oKXMAEJaNZ+mPjCma4+WLkkaX9YPWrIMIKRVczjw\npPb0WZJsBdwd+GmSY5P8JMnpSXYf/mCSXZIc2Zn+QJK92/sHJflOklOSHJ1ks7nYGEnSrLF+0JJl\nACGtglLKFdQnSD6xJe0BfA74M/C0UsoOwKOA9yZJn2UmWRP4L+CZpZQHAQcDb5/tskuSRsf6QUvZ\nGvNdAGkJGDRTf6X9fT4Q4B1JHgHcCmwObApc3GN59wbuBxzT6pTVgYtmv9iSpBGzftCSZAAhrbqv\nAO9PsgOwbinllNbUvDHwoFLKTUnOA+4w9LmbWbEVcDA/wM9LKQ8bbbElSSNm/aAlyS5M0ioqpVwD\nHEdtSh7cHLcBcGmrHB4F3HOCj54P3DfJ2kk2BB7T0s8ENk7yMKhN1kn+aqQbIUmaddYPWqpsgZBm\nx6eBL/H/27ljE4RiKAyj/53A5RxM3MHG1jWEV6hgZ+EWNrFQeGB1C0WUc8pAIClC+CBk/nFjk2RX\nVYck+yTn1wljjGtVbZMck1ySTM/xW1Utk6yrapHHOV0lOX18FwC8m/uBv1NjjG+vAQAA+BGeMAEA\nAIVfT+kAAAAsSURBVG0CAgAAaBMQAABAm4AAAADaBAQAANAmIAAAgDYBAQAAtAkIAACg7Q67WtJh\n1lQp5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11307a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividindo os dados entre features e coluna alvo\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n",
    "\n",
    "# Visualizando os principais desvios das colunas contínuas entre os dados\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para atributos com distribuição muito distorcida, tais como `'capital-gain'` e `'capital-loss'`, é uma prática comum aplicar uma <a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">transformação logarítmica</a> nos dados para que os valores muito grandes e muito pequenos não afetem a performance do algoritmo de aprendizado. Usar a transformação logarítmica reduz significativamente os limites dos valores afetados pelos outliers (valores muito grandes ou muito pequenos). Deve-se tomar cuidado ao aplicar esta transformação, poir o logaritmo de `0` é indefinido, portanto temos que incrementar os valores em uma pequena quantia acima de `0` para aplicar o logaritmo adequadamente.\n",
    "\n",
    "Execute o código da célula abaixo para realizar a transformação nos dados e visualizar os resultados. De novo, note os valores limite e como os valores estão distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1107d3a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicando a transformação de log nos registros distorcidos.\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualizando as novas distribuições após a transformação.\n",
    "vs.distribution(features_log_transformed, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando atributos numéricos\n",
    "Além das transformações em atributos distorcidos, é uma boa prática comum realizar algum tipo de adaptação de escala nos atributos numéricos. Ajustar a escala nos dados não modifica o formato da distribuição de cada coluna (tais como `'capital-gain'` ou `'capital-loss'` acima); no entanto, a normalização garante que cada atributo será tratado com o mesmo peso durante a aplicação de aprendizado supervisionado. Note que uma vez aplicada a escala, a observação dos dados não terá o significado original, como exemplificado abaixo.\n",
    "\n",
    "Execute o código da célula abaixo para normalizar cada atributo numérico, nós usaremos ara isso a [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Inicializando um aplicador de escala e aplicando em seguida aos atributos\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Exibindo um exemplo de registro com a escala aplicada\n",
    "display(features_log_minmax_transform.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Pré-processamento dos dados\n",
    "\n",
    "A partir da tabela em **Explorando os dados** acima, nós podemos observar que existem diversos atributos não-numéricos para cada registro. Usualmente, algoritmos de aprendizado esperam que os inputs sejam numéricos, o que requer que os atributos não numéricos (chamados de *variáveis de categoria*) sejam convertidos. Uma maneira popular de converter as variáveis de categoria é utilizar a estratégia **one-hot encoding**. Esta estratégia cria uma variável para cada categoria possível de cada atributo não numérico. Por exemplo, assuma que `algumAtributo` possuí três valores possíveis: `A`, `B`, ou `C`. Nós então transformamos este atributo em três novos atributos: `algumAtributo_A`, `algumAtributo_B` e `algumAtributo_C`.\n",
    "\n",
    "\n",
    "|   | algumAtributo |                    | algumAtributo_A | algumAtributo_B | algumAtributo_C |\n",
    "| :-: | :-: |                            | :-: | :-: | :-: |\n",
    "| 0 |  B  |  | 0 | 1 | 0 |\n",
    "| 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |\n",
    "| 2 |  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "Além disso, assim como os atributos não-numéricos, precisaremos converter a coluna alvo não-numérica, `'income'`, para valores numéricos para que o algoritmo de aprendizado funcione. Uma vez que só existem duas categorias possíveis para esta coluna (\"<=50K\" e \">50K\"), nós podemos evitar a utilização do one-hot encoding e simplesmente transformar estas duas categorias para `0` e `1`, respectivamente. No trecho de código abaixo, você precisará implementar o seguinte:\n",
    " - Utilizar [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para realizar o one-hot encoding nos dados da `'features_log_minmax_transform'`.\n",
    " - Converter a coluna alvo `'income_raw'` para re.\n",
    "   - Transforme os registros com \"<=50K\" para `0` e os registros com \">50K\" para `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n",
      "['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass_ Federal-gov', 'workclass_ Local-gov', 'workclass_ Private', 'workclass_ Self-emp-inc', 'workclass_ Self-emp-not-inc', 'workclass_ State-gov', 'workclass_ Without-pay', 'education_level_ 10th', 'education_level_ 11th', 'education_level_ 12th', 'education_level_ 1st-4th', 'education_level_ 5th-6th', 'education_level_ 7th-8th', 'education_level_ 9th', 'education_level_ Assoc-acdm', 'education_level_ Assoc-voc', 'education_level_ Bachelors', 'education_level_ Doctorate', 'education_level_ HS-grad', 'education_level_ Masters', 'education_level_ Preschool', 'education_level_ Prof-school', 'education_level_ Some-college', 'marital-status_ Divorced', 'marital-status_ Married-AF-spouse', 'marital-status_ Married-civ-spouse', 'marital-status_ Married-spouse-absent', 'marital-status_ Never-married', 'marital-status_ Separated', 'marital-status_ Widowed', 'occupation_ Adm-clerical', 'occupation_ Armed-Forces', 'occupation_ Craft-repair', 'occupation_ Exec-managerial', 'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct', 'occupation_ Other-service', 'occupation_ Priv-house-serv', 'occupation_ Prof-specialty', 'occupation_ Protective-serv', 'occupation_ Sales', 'occupation_ Tech-support', 'occupation_ Transport-moving', 'relationship_ Husband', 'relationship_ Not-in-family', 'relationship_ Other-relative', 'relationship_ Own-child', 'relationship_ Unmarried', 'relationship_ Wife', 'race_ Amer-Indian-Eskimo', 'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White', 'sex_ Female', 'sex_ Male', 'native-country_ Cambodia', 'native-country_ Canada', 'native-country_ China', 'native-country_ Columbia', 'native-country_ Cuba', 'native-country_ Dominican-Republic', 'native-country_ Ecuador', 'native-country_ El-Salvador', 'native-country_ England', 'native-country_ France', 'native-country_ Germany', 'native-country_ Greece', 'native-country_ Guatemala', 'native-country_ Haiti', 'native-country_ Holand-Netherlands', 'native-country_ Honduras', 'native-country_ Hong', 'native-country_ Hungary', 'native-country_ India', 'native-country_ Iran', 'native-country_ Ireland', 'native-country_ Italy', 'native-country_ Jamaica', 'native-country_ Japan', 'native-country_ Laos', 'native-country_ Mexico', 'native-country_ Nicaragua', 'native-country_ Outlying-US(Guam-USVI-etc)', 'native-country_ Peru', 'native-country_ Philippines', 'native-country_ Poland', 'native-country_ Portugal', 'native-country_ Puerto-Rico', 'native-country_ Scotland', 'native-country_ South', 'native-country_ Taiwan', 'native-country_ Thailand', 'native-country_ Trinadad&Tobago', 'native-country_ United-States', 'native-country_ Vietnam', 'native-country_ Yugoslavia']\n"
     ]
    }
   ],
   "source": [
    "# Utilize o one-hot encoding nos dados em 'features_log_minmax_transform' utilizando pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_raw)\n",
    "\n",
    "# Faça o encode da coluna 'income_raw' para valores numéricos\n",
    "income = income_raw.apply(lambda x: 0 if x == \"<=50K\" else 1)\n",
    "\n",
    "# Exiba o número de colunas depois do one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Descomente a linha abaixo para ver as colunas após o encode\n",
    "#print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embaralhar e dividir os dados\n",
    "Agora todas as _variáveis de categoria_ foram convertidas em atributos numéricos e todos os atributos numéricos foram normalizados. Como sempre, nós agora dividiremos os dados entre conjuntos de treinamento e de teste. 80% dos dados serão utilizados para treinamento e 20% para teste.\n",
    "\n",
    "Execute o código da célula abaixo para realizar divisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alteração realizada**: para que a proporção nos datasets seja preservada, devemos fazer uma amostragem estratificada. Em `'train_test_split'`, isto pode ser feito inserindo-se o parâmetro `'stratify=y_all'`. Desta forma, a apresentação de resultados será mais consistente com a realidade e teremos maior confiança sobre a influência de parâmetros no modelo final. A amostragem continua sendo aleatória, no entanto com a proporção de classes preservada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Importar train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os 'atributos' e 'income' entre conjuntos de treinamento e de testes.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income,\n",
    "                                                    stratify=income,\n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Avaliando a performance do modelo\n",
    "Nesta seção nós investigaremos quatro algoritmos diferentes e determinaremos qual deles é melhor para a modelagem dos dados. Três destes algoritmos serão algoritmos de aprendizado supervisionado de sua escolha e o quarto algoritmo é conhecido como *naive predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas e o Naive predictor\n",
    "\n",
    "*CharityML*, equpada com sua pesquisa, sabe que os indivíduos que fazem mais do que \\$50,000 possuem maior probabilidade de doar para a sua campanha de caridade. Por conta disto, a *CharityML* está particularmente interessada em predizer com acurácia quais indivíduos possuem remuneração acima de \\$50,000. Parece uqe utilizar **acurácia (accuracy)** como uma métrica para avaliar a performance de um modelo é um parâmetro adequado. Além disso, identificar alguém que *não possui* remuneração acima de \\$50,000 como alguém que recebe acima deste valor seria ruim para a *CharityML*, uma vez que eles estão procurando por indivíduos que desejam doar. Com isso, a habilidade do modelo em predizer com preisão aqueles que possuem a remuneração acima dos \\$50,000 é *mais importante* do que a habilidade de realizar o **recall** destes indivíduos. Nós podemos utilizar a fórmula **F-beta score** como uma métrica que considera ambos: precision e recall.\n",
    "\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "Em particular, quando $\\beta = 0.5$, maior ênfase é atribuída para a variável precision. Isso é chamado de **F$_{0.5}$ score** (ou F-score, simplificando).\n",
    "\n",
    "Analisando a distribuição de classes (aqueles que possuem remuneração até \\$50,000 e aqueles que possuem remuneração superior), fica claro que a maioria dos indivíduos não possui remuneração acima de \\$50,000. Isto pode ter grande impacto na **acurácia (accuracy)**, uma vez que nós poderíamos simplesmente dizer *\"Esta pessoa não possui remuneração acima de \\$50,000\"* e estar certos em boa parte das vezes, sem ao menos olhar os dados! Fazer este tipo de afirmação seria chamado de **naive**, uma vez que não consideramos nenhuma informação para balisar este argumento. É sempre importante considerar a *naive prediction* para seu conjunto de dados, para ajudar a estabelecer um benchmark para análise da performance dos modelos. Com isso, sabemos que utilizar a naive prediction não traria resultado algum: Se a predição apontasse que todas as pessoas possuem remuneração inferior à \\$50,000, a *CharityML* não identificaria ninguém como potencial doador. \n",
    "\n",
    "\n",
    "\n",
    "#### Nota: Revisando: accuracy, precision e recall\n",
    "\n",
    "** Accuracy ** mede com que frequência o classificador faz a predição correta. É a proporção entre o número de predições corretas e o número total de predições (o número de registros testados).\n",
    "\n",
    "** Precision ** informa qual a proporção de mensagens classificamos como spam eram realmente spam. Ou seja, é a proporção de verdadeiros positivos (mensagens classificadas como spam que eram realmente spam) sobre todos os positivos (todas as palavras classificadas como spam, independente se a classificação estava correta), em outras palavras, é a proporção\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso positivos)]`\n",
    "\n",
    "** Recall(sensibilidade)** nos informa qual a proporção das mensagens que eram spam que foram corretamente classificadas como spam. É a proporção entre os verdadeiros positivos (classificados como spam, que realmente eram spam) sobre todas as palavras que realmente eram spam. Em outras palavras, é a proporção entre\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso negativos)]`\n",
    "\n",
    "Para problemas de classificação distorcidos em suas distribuições, como no nosso caso, por exemplo, se tivéssemos 100 mensagems de texto e apenas 2 fossem spam e todas as outras não fossem, a \"accuracy\" por si só não seria uma métrica tão boa. Nós poderiamos classificar 90 mensagems como \"não-spam\" (incluindo as 2 que eram spam mas que teriam sido classificadas como não-spam e, por tanto, seriam falso negativas.) e 10 mensagems como spam (todas as 10 falso positivas) e ainda assim teriamos uma boa pontuação de accuracy. Para estess casos, precision e recall são muito úteis. Estas duas métricas podem ser combinadas para resgatar o F1 score, que é calculado através da média(harmônica) dos valores de precision e de recall. Este score pode variar entre 0 e 1, sendo 1 o melhor resultado possível para o F1 score (consideramos a média harmônica pois estamos lidando com proporções)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.2478, F-score: 0.2917]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TP = np.sum(income) # Contando pois este é o caso \"naive\". Note que 'income' são os dados 'income_raw' convertidos\n",
    "para valores numéricos durante o passo de pré-processamento de dados.\n",
    "FP = income.count() - TP # Específico para o caso naive\n",
    "\n",
    "TN = 0 # Sem predições negativas para o caso naive\n",
    "FN = 0 # Sem predições negativas para o caso naive\n",
    "'''\n",
    "# Calcular accuracy, precision e recall\n",
    "accuracy = greater_percent/100 # TP/total\n",
    "recall = n_greater_50k/(n_greater_50k + 0) # TP/(TP+FN)\n",
    "precision = n_greater_50k/(n_greater_50k + n_at_most_50k) # TP/(TP+FP)\n",
    "\n",
    "# Calcular o F-score utilizando a fórmula acima para o beta = 0.5 e os valores corretos de precision e recall.\n",
    "beta = 0.5\n",
    "fscore = ((1+beta*beta)*(precision*recall)) / (beta*beta*precision + recall)\n",
    "\n",
    "# Exibir os resultados \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Performance do Naive Predictor\n",
    "* Se escolhessemos um modelo que sempre prediz que um indivíduo possui remuneração acima de $50,000, qual seria a accuracy e o F-score considerando este conjunto de dados? Você deverá utilizar o código da célula abaixo e atribuir os seus resultados para as variáveis `'accuracy'` e `'fscore'` que serão usadas posteriormente.\n",
    "\n",
    "** Por favor, note ** que o propósito ao gerar um naive predictor é simplesmente exibir como um modelo sem nenhuma inteligência se comportaria. No mundo real, idealmente o seu modelo de base será o resultado de um modelo anterior ou poderia ser baseado em um paper no qual você se basearia para melhorar. Quando não houver qualquer benchmark de modelo, utilizar um naive predictor será melhor do que uma escolha aleatória.\n",
    "\n",
    "** DICA: ** \n",
    "\n",
    "* Quando temos um modelo que sempre prediz '1' (e.x o indivíduo possui remuneração superior à 50k) então nosso modelo não terá Verdadeiros Negativos ou Falso Negativos, pois nós não estaremos afirmando que qualquer dos valores é negativo (ou '0') durante a predição. Com isso, nossa accuracy neste caso se torna o mesmo valor da precision (Verdadeiros positivos/ (Verdadeiros positivos + Falso positivos)) pois cada predição que fizemos com o valor '1' que deveria ter o valor '0' se torna um falso positivo; nosso denominador neste caso é o número total de registros.\n",
    "* Nossa pontuação de Recall(Verdadeiros positivos/(Verdadeiros Positivos + Falsos negativos)) será 1 pois não teremos Falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** obtivemos os seguintes valores para o `Naive Predictor: [Accuracy score: 0.2478, F-score: 0.2917]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelos de Aprendizado Supervisionado\n",
    "**Estes são alguns dos modelos de aprendizado supervisionado disponíveis em** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees (Árvores de decisão)\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação do Modelo\n",
    "Liste três dos modelos de aprendizado supervisionado acima que são apropriados para este problema que você irá testar nos dados do censo. Para cada modelo escolhido\n",
    "\n",
    "- Descreva uma situação do mundo real onde este modelo pode ser utilizado. \n",
    "- Quais são as vantagems da utilização deste modelo; quando ele performa bem?\n",
    "- Quais são as fraquesas do modelo; quando ele performa mal?\n",
    "- O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?\n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Estruture sua resposta no mesmo formato acima^, com 4 partes para cada um dos modelos que você escolher. Por favor, inclua referências em cada uma das respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml_map.png\"/>\n",
    "\n",
    "**Resposta: **Para lidar com o problema de **classificação**, os seguintes modelos são apropriados:Regressão Logística, Naive Bayes e SVM.\n",
    "\n",
    "### **Regressão Logística**\n",
    "- **Aplicação: **É um dos modelos mais simples de classificação, e funciona muito bem quando os dados são *linearmente separáveis*. Uma aplicação desse modelo é na classificação de alunos a serem aceitos ou não em uma universidade baseados em suas notas, por exemplo. Também pode ser usado em diversas aplicações médicas de diagnóstico e curiosamente prever medidas de segurança para minas de carvão.\n",
    "- **Vantagens: **\n",
    "    - As saídas têm uma boa interpretação probabilística e o algoritmo pode ser ajustado para evitar o overfitting; \n",
    "    - Os modelos logísticos podem ser atualizados facilmente com novos dados usando Método do gradiente estocástico (SGDC); \n",
    "    - Simples, funciona muito bem quando os dados são linearmente separáveis.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - O conjunto de dados do problema precisa ser linearmente separável; \n",
    "    - A regressão logística tende a ter uma performance inferior quando existem limites de decisão múltiplos ou não-lineares; \n",
    "    - Eles não são flexíveis o suficiente para capturar naturalmente relacionamentos mais complexos.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **A aplicação desse modelo para o problema é bastante promissora pois a Regressão Logística se aplica para problemas como o desse projeto (que inclusive se parece com o exemplificado), embora não dê para saber se os dados são linearmente separáveis. Isso somente será possível de avaliar durante os testes a seguir. Além disso, inspirando-se no princípio da *Navalha de Occam*, é bom começar com poucas premissas e com um modelo bem básico como referência para depois avaliar modelos mais complexos.\n",
    "\n",
    "<img src=\"logistic.png\" width=\"35%\"/>\n",
    "\n",
    "### **Gaussian Naive Bayes (GaussianNB)**\n",
    "- **Aplicação: **É um algoritmo muito simples em torno de probabilidade condicional e contagem. Basicamente é uma tabela de probabilidade, que se assemelha estruturalmente a uma Árvode de Decisão, atualizada com o treinamento. o Naive (que significa `\"ingênuo\"`) pois considera *independência dos dados* (dos atributos) o que raramente ocorre no mundo real. Esse modelo é bastante eficiente e utilizado em classificação de documentos (especialmente em classificação de SPAM, como é usado pelo Google no GMail), classificação de textos (como notícias que o usuário possa gostar em seu feed e *trend topics*), a sugestão de autocompletar em textos, como teclados de celular e *sentimental analysis* (de Tweets, por exemplo, identificando expressões negativas e positivas em textos). Assim como a Regressão Logística, tem sucesso em algumas aplicações médicas (prever doenças) e biológicas.\n",
    "- **Vantagens: **\n",
    "    - Funciona bem para Datasets com muitos atributos e quando os dados são categóricos;\n",
    "    - É um algoritmo muito rápido para treinamento;\n",
    "    - Como precisa de poucos parâmetros, é menos suscetível à overfitting;\n",
    "    - Separa bem o ruído nos dados.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Ele precisa de um Dataset moderado para treinamento;\n",
    "    - Os atributos precisam ser independentes entre si;\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Como o Dataset possui muitos atributos, e um número bom de dados, parece ser interessante usar o Naive Bayes, até porque para verificar se é um bom modelo exigirá pouco esforço computacional. No entanto, não é possível saber se todas os atributos são independentes entre si, o que poderá ser verificado apenas com o resultado final da modelagem, comparando-se o score com os demais modelos.\n",
    "\n",
    "### **Máquinas de Vetores de Suporte (SVM)**\n",
    "- **Aplicação: **Esse modelo utiliza kernels, que aprendem a diferenciar duas categorias de dados com base em similaridades de exemplos passados, determinando uma borda de decisão que maximiza a distancia entre os membros mais próximos das categorias. Os exemplos de uso são parecidos com os da Regressão Logística, mas agora sem a restrição dos dados serem linearmente separáveis. São usados portanto em reconhecimento de escrita (mais do que Redes Neurais), reconhecimento facial, e classificação de imagens. Além disso, pode ser usado para prever dinâmicas de mercados e previsões financeiras.  \n",
    "- **Vantagens: **\n",
    "    - Consegue lidar com dados não-lineares;\n",
    "    - Não é necessário tomar premissas sobre o relacionamento entre os dados (como Regressão Logística e Naive Bayes o fazem);\n",
    "    - Geralmente resulta em modelos com melhor classificação de valores futuros;\n",
    "    - Possui diversos kernels;\n",
    "    - Bastante robusto contra overfitting, especialmente em espaços multi-dimensionais;\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Computacionalmente, exige bastante memória;\n",
    "    - Exige uma certa habilidade em escolher o melhor kernel para modelar a solução do probblema;\n",
    "    - Não escala muito bem bara grandes bases de dados;\n",
    "    - É mais utilizado como um classificador binário (que é como ele funciona melhor). Não funciona bem para problemas multi-classe;\n",
    "    - Atualmente, na indústria, tem-se preferido utilizar Random Forest ao invés de SVM.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Como o nosso problema é binário, o Dataset é de volume moderado, e não temos certeza se a Regressão Linear funcionará (ou seja, é uma alternativa boa se os dados não forem linearmente separáveis), o uso do SVM é interessante para esse problema. No entanto, escolher o melhor kernel deverá ser um ponto de atenção. O SGDC (*Stochastic Gradient Descent Classifier*) segue raciocínio similar.\n",
    "\n",
    "<img src=\"svm.png\" width=\"35%\"/>\n",
    "\n",
    "No entanto, segue uma análise dos demais métodos.\n",
    "\n",
    "### **Árvores de Decisão (e suas variações: Gradient/Decision boosting, Random/Decision Forest )**\n",
    "- **Aplicação: **Também conhecidas como *Árvores de Classificação*, é um modelo bastante intuitivo graficamente ou programáticamente (através de *if-then statements*). Funciona muito bem quando os dados podem ser bem divididos a cada camada de decisão. Uma aplicação desse modelo é em que partido um eleitor vai votar, baseada em suas características como idade, sexo, classe social, etc. Ou, da mesma forma, é um excelente classificador para prever se um usuário vai assinar ou não um plano pago (*user signup*) de algum serviço ou até mesmo o funil/pipeline que o leva a tomar essa ação. Também pode ser utilizado para ranking, como no Netflix. Tem sido utilizado também com sucesso em problemas de reconhecimento de voz através de otimização e pruning de árvores. Tem aplicações também em sensoriamento remoto.\n",
    "- **Vantagens: **\n",
    "    - Devido à sua estrutura natural, escala bem e lida muito bem com dados não-lineares;\n",
    "    - Rápido de treinar e de visualizar o resultado e robusta a erros;\n",
    "    - Lida bem com dados categóricos e numéricos;\n",
    "    - Não é necessário tomar premissas sobre o relacionamento entre os dados (como Regressão Logística e Naive Bayes o fazem).\n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Podem crescer muito rápido de estrutura com Datasets grandes, causando overfitting (o que pode ser aliviado pelos métodos de *ensemble*);\n",
    "    - Geralmente resulta em modelos menos generalizados;\n",
    "    - Também usa bastante memória;\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Esse modelo, também simples, consegue lidar com dados que não são linearmente separáveis e categóricos. Além disso, existem muitos atributos cujos valores podem ser interpretados como \"0/1\" ou \"não/sim\", o que é perfeito para esse método. No entanto, ainda é uma dúvida se pelo tamanho do Dataset poderá resultar em um overfit ou ser serão necessárias técnicas de *ensemble* para contornar esse possível problema e ajudar a prever as amostras mais difíceis. \n",
    "\n",
    "<img src=\"tree.png\" width=\"35%\"/>\n",
    "\n",
    "### **Deep Learning (Redes Neurais)**\n",
    "- **Aplicação: **Inspirado no funcionamento do cérebro humano, esse clasificador de muitas maneiras faz a ponte entre o aprendizado de máquina e a ciência cognitiva, sendo bastante conveniente para classificação. Como principal aplicação do Deep Learning (utilizando MLP - *Multi Layer Perceptron* conectados por `\"sinapses\"`) temos o reconhecimento de imagens e de audio, principalmente com o aumento da capacidade de processamento de dados atual, bem como reconhecimento de movimento (andar, percurso de carros autônomos, voos de autônomos), também aplicações médicas, e até tradução de textos (Google Translator).\n",
    "- **Vantagens: **\n",
    "    - Possui muitos parâmetros se comparados aos outros métodos, o que lhe confere bastante versatilidade;\n",
    "    - Possui alta escalabilidade;\n",
    "    - Eficiente no uso de memória.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Pode tomar muito tempo e recursos computacionais para treinamento (para evitar *extremos locais* e outras situações típicas desse modelo);\n",
    "    - Precisa de bastante dados para treinamento;\n",
    "    - É uma caixa preta, ou seja, difícil de visualizar a estrutura final de uma rede neural;\n",
    "    - Alto nível de complexidade na modelagem.\n",
    "    \n",
    "    \n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **Para esse problema, acho que iríamos cair em uma situação de `\"Matar uma mosca com uma bazooka\"`. Apesar de ser interessante usar uma Rede Neural para resolver esse problema, acredito que ele possa ser resolvido com métodos mais simples.\n",
    "\n",
    "<img src=\"nn.png\" width=\"35%\"/>\n",
    "\n",
    "### **K-Nearest Neighbors (K-NN)**\n",
    "- **Aplicação: **É uma classe de algoritmos especializados, denominada de *instance-based*, quando o problema exige uma objetivo bastante específico  ou uma *clusterização* do conjunto de dados, e utiliza funções que calculam similaridade dos dados com base em uma medida de *distância* entre eles. Geralmente é utilizada em aprendizagem não supervisionada, mas no campo da aprendizagem supervisionada uma aplicação bastante interessante para o K-NN é a detecção de anomalias nos dados (ou no modelo de agrupamento deles), como por exemplo detecção de fraudes e outras vulnerabilidades de segurança.\n",
    "- **Vantagens: **\n",
    "    - Consegue lidar com funções numericamente complexas;\n",
    "    - Útil quando o dado é difícil/caro de se obter, pois ao longo do processo de escala do modelo, pode-se revelar que dados são úteis ou não de se coletar.\n",
    "    \n",
    "    \n",
    "- **Desvantagens: **\n",
    "    - Usam intensivamente a memória (muitas vezes até Bancos de Dados - *instance-based*);\n",
    "    - Requer todos os dados treinamento para realizar a previsão;\n",
    "    - Encontrar as funções de distância pode ser computacionalmente intensivo.\n",
    "    \n",
    "\n",
    "- **O que faz ele um bom candidado para o problema, baseado nos dados: **No problema em questão até poderia ser utilizado para clusterizar o Dataset e encontrar a função de distância. No entanto, acredito que seja também uma situação de `\"Matar uma mosca com uma bazooka\"`.\n",
    "\n",
    "<img src=\"knn.png\" width=\"35%\"/>\n",
    "\n",
    ">Modern Machine Learning Algorithms: Strengths and Weaknesses, URL: https://elitedatascience.com/machine-learning-algorithms#classification\n",
    "\n",
    ">Machine Learning Algorithms for Business Applications – Complete Guide, URL: https://www.techemergence.com/machine-learning-algorithms-for-business-applications-complete-guide/\n",
    "\n",
    ">How to choose algorithms for Microsoft Azure Machine Learning, URL: https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice\n",
    "\n",
    ">Complete Guide to Parameter Tuning in XGBoost (with codes in Python), URL: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    ">Xgboost, URL: https://en.wikipedia.org/wiki/Xgboost\n",
    "\n",
    ">Machine Learning, do Vale do Silício ao Brasil, URL: https://www.youtube.com/watch?v=AJdoVmhAxUk&feature=youtu.be&t=1h37m28s\n",
    "\n",
    ">Installing XGBoost on Mac OSX, URL: https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_on_Mac_OSX?lang=en\n",
    "\n",
    ">XGBoost Installation Guide, URL: http://xgboost.readthedocs.io/en/latest/build.html#python-package-installation\n",
    "\n",
    ">How to Develop Your First XGBoost Model in Python with scikit-learn, URL: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Criando um Pipeline de Treinamento e Predição\n",
    "Para avaliar adequadamente a performance de cada um dos modelos que você escolheu é importante que você crie um pipeline de treinamento e predição que te permite de maneira rápida e eficiente treinar os modelos utilizando vários tamanhos de conjuntos de dados para treinamento, além de performar predições nos dados de teste. Sua implementação aqui será utilizada na próxima seção. No bloco de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar `fbeta_score` e `accuracy_score` de [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Adapte o algoritmo para os dados de treinamento e registre o tempo de treinamento. \n",
    " - Realize predições nos dados de teste `X_test`, e também nos 300 primeiros pontos de treinamento `X_train[:300]`.\n",
    "   - Registre o tempo total de predição. \n",
    " - Calcule a acurácia tanto para o conjundo de dados de treino quanto para o conjunto de testes.\n",
    " - Calcule o F-score para os dois conjuntos de dados: treino e testes. \n",
    "   - Garanta que você configurou o parâmetro `beta`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5)\n",
    "        \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5)\n",
    "    \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Validação inicial do modelo\n",
    "No código da célular, você precisará implementar o seguinte:\n",
    "- Importar os três modelos de aprendizado supervisionado que você escolheu na seção anterior \n",
    "- Inicializar os três modelos e armazená-los em `'clf_A'`, `'clf_B'`, e `'clf_C'`. \n",
    "  - Utilize um `'random_state'` para cada modelo que você utilizar, caso seja fornecido.\n",
    "  - **Nota:** Utilize as configurações padrão para cada modelo - você otimizará um modelo específico em uma seção posterior\n",
    "- Calcule o número de registros equivalentes à 1%, 10%, e 100% dos dados de treinamento.\n",
    "  - Armazene estes valores em `'samples_1'`, `'samples_10'`, e `'samples_100'` respectivamente.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo de sua escolha, a implementação abaixo pode demorar algum tempo para executar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alteração realizada**: foi necessário alterar o nome da função `visuals.evaluate` para `visuals.evaluate_plot` para corrigir um erro que estava sendo gerado pelo arquivo original no Python 3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 361 samples.\n",
      "LogisticRegression trained on 3617 samples.\n",
      "LogisticRegression trained on 36177 samples.\n",
      "GaussianNB trained on 361 samples.\n",
      "GaussianNB trained on 3617 samples.\n",
      "GaussianNB trained on 36177 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 361 samples.\n",
      "SVC trained on 3617 samples.\n",
      "SVC trained on 36177 samples.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAIuCAYAAAAv/u6UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmS1DMLCEmSJEk9s4CQJEmS1LP/AD9uAykQ7LvWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1058c2a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importe os três modelos de aprendizado supervisionado da sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Inicialize os três modelos\n",
    "clf_A = LogisticRegression()\n",
    "clf_B = GaussianNB()\n",
    "clf_C = SVC()\n",
    "\n",
    "# Calcule o número de amostras para 1%, 10%, e 100% dos dados de treinamento\n",
    "# HINT: samples_100 é todo o conjunto de treinamento e.x.: len(y_train)\n",
    "# HINT: samples_10 é 10% de samples_100\n",
    "# HINT: samples_1 é 1% de samples_100\n",
    "samples_100 = X_train.shape[0]\n",
    "samples_10 = int(.1*X_train.shape[0])\n",
    "samples_1 = int(.01*X_train.shape[0])\n",
    "\n",
    "# Colete os resultados dos algoritmos de aprendizado\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate_plot(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Melhorando os resultados\n",
    "Nesta seção final, você irá escolher o melhor entre os três modelos de aprendizado supervisionado para utilizar nos dados dos estudantes. Você irá então realizar uma busca grid para otimização em todo o conjunto de dados de treino (`X_train` e `y_train`) fazendo o tuning de pelo menos um parâmetro para melhorar o F-score anterior do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o melhor modelo\n",
    "\n",
    "* Baseado na validação anterior, em um ou dois parágrafos explique para a *CharityML* qual dos três modelos você acredita ser o mais apropriado para a tarefa de identificar indivíduos com remuneração anual superior à \\$50,000.  \n",
    "\n",
    "** DICA: ** \n",
    "Analise o gráfico do canto inferior esquerdo da célula acima(a visualização criada através do comando `vs.evaluate(results, accuracy, fscore)`) e verifique o F score para o conjunto de testes quando 100% do conjunto de treino é utilizado. Qual modelo possui o maior score? Sua resposta deve abranger os seguintes pontos:\n",
    "* métricas - F score no conjunto de testes quando 100% dos dados de treino são utilizados, \n",
    "* tempo de predição/treinamento \n",
    "* a adequação do algoritmo para este cojunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1%</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.820122</td>\n",
       "      <td>0.838695</td>\n",
       "      <td>0.841791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_test</th>\n",
       "      <td>0.640586</td>\n",
       "      <td>0.681865</td>\n",
       "      <td>0.691186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_train</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.707237</td>\n",
       "      <td>0.740132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.006454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.020490</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.512739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1%       10%      100%\n",
       "acc_test    0.820122  0.838695  0.841791\n",
       "acc_train   0.896667  0.863333  0.876667\n",
       "f_test      0.640586  0.681865  0.691186\n",
       "f_train     0.803571  0.707237  0.740132\n",
       "pred_time   0.036284  0.007690  0.006454\n",
       "train_time  0.020490  0.032592  0.512739"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1%</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.752128</td>\n",
       "      <td>0.833941</td>\n",
       "      <td>0.841349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_test</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679131</td>\n",
       "      <td>0.694040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.295736</td>\n",
       "      <td>2.610976</td>\n",
       "      <td>26.551529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.032147</td>\n",
       "      <td>1.459044</td>\n",
       "      <td>141.920902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1%       10%        100%\n",
       "acc_test    0.752128  0.833941    0.841349\n",
       "acc_train   0.773333  0.840000    0.850000\n",
       "f_test      0.000000  0.679131    0.694040\n",
       "f_train     0.000000  0.653846    0.678571\n",
       "pred_time   0.295736  2.610976   26.551529\n",
       "train_time  0.032147  1.459044  141.920902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1%</th>\n",
       "      <th>10%</th>\n",
       "      <th>100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.356993</td>\n",
       "      <td>0.594030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_test</th>\n",
       "      <td>0.380323</td>\n",
       "      <td>0.319645</td>\n",
       "      <td>0.421005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_train</th>\n",
       "      <td>0.397196</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.390244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.030765</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>0.127844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1%       10%      100%\n",
       "acc_test    0.530017  0.356993  0.594030\n",
       "acc_train   0.570000  0.310000  0.573333\n",
       "f_test      0.380323  0.319645  0.421005\n",
       "f_train     0.397196  0.288793  0.390244\n",
       "pred_time   0.041225  0.030765  0.030297\n",
       "train_time  0.002746  0.019337  0.127844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing out the values\n",
    "for i in results.items():\n",
    "    print(i[0])\n",
    "    display(pd.DataFrame(i[1]).rename(columns={0:'1%', 1:'10%', 2:'100%'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Baseados nos experimentos executados, o melhor modelo para a CharityML é a **Regressão Logística**. Isso porque tanto o f1 score de treino quanto o de teste se mostraram superiores aos demais modelos testados. Esse resultado também indica que os dados são linearmente separáveis, e um modelo como a Regressão Logística se mostrou adequado para resolver o problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 - Descrevendo o modelo nos termos de Layman\n",
    " \n",
    "* Em um ou dois parágrafos, explique para a *CharityML*, nos termos de layman, como o modelo final escolhido deveria funcionar. Garanta que você está descrevendo as principais vantagens do modelo, tais como o modo de treinar o modelo e como o modelo realiza a predição. Evite a utilização de jargões matemáticos avançados, como por exemplo a descrição de equações. \n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Quando estiver explicando seu modelo, cite as fontes externas utilizadas, caso utilize alguma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** - a Regressão Logística é um dos modelos mais simples de classificação, e funciona muito bem quando os dados são *linearmente separáveis*. Uma aplicação desse modelo é na classificação de alunos a serem aceitos ou não em uma universidade baseados em suas notas, por exemplo.\n",
    "\n",
    "<img src=\"logistic.png\" width=\"35%\"/>\n",
    "\n",
    "No nosso exemplo, esses dois grupos podem ser pensados como o grupo daqueles que possuem remuneração acima de 50,000.00 e aqueles que não. O algoritmo de Regresão Logística (classificador na variável `'clf'`), então, buscou encontrar uma uma borda de decisão (acima representada pela curva) que separasse os grupos da forma mais generalizada possível.\n",
    "\n",
    "Assim, para avaliar se uma pessoa ganha mais de 50,000.00, basta entrar com o vetor que representa as características dessa pessoa (X) e utilizar a função `clf.predict(X)` e verificar qual o resultado produzido: `\"0\"` ele pertence ao grupo daqueles que ganham menos que 50,000.00 `\"1\"` ele pertence ao grupo daqueles que ganham mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Tuning do modelo\n",
    "Refine o modelo escolhido. Utilize uma busca grid (`GridSearchCV`) com pleo menos um parâmetro importante refinado com pelo menos 3 valores diferentes. Você precisará utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você precisará implementar o seguinte:\n",
    "- Importar [`sklearn.grid_search.GridSearchCV`](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Inicializar o classificador escolhido por você e armazená-lo em `clf`.\n",
    " - Configurar um `random_state` se houver um disponível para o mesmo estado que você configurou anteriormente.\n",
    "- Criar um dicionário dos parâmetros que você quer otimizar para o modelo escolhido.\n",
    " - Exemplo: `parâmetro = {'parâmetro' : [lista de valores]}`.\n",
    " - **Nota:** Evite otimizar o parâmetro `max_features` se este parâmetro estiver disponível! \n",
    "- Utilize `make_scorer` para criar um objeto de pontuação `fbeta_score` (com $\\beta = 0.5$).\n",
    "- Realize a busca gride no classificador `clf` utilizando o `'scorer'` e armazene-o na variável `grid_obj`.   \n",
    "- Adeque o objeto da busca grid aos dados de treino (`X_train`, `y_train`) e armazene em `grid_fit`.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo escolhido e da lista de parâmetros, a implementação a seguir pode levar algum tempo para executar! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] solver=newton-cg, class_weight=None, C=1 ........................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=1, score=0.689880 -   2.4s\n",
      "[CV] solver=newton-cg, class_weight=None, C=1 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, class_weight=None, C=1, score=0.687934 -   1.8s\n",
      "[CV] solver=newton-cg, class_weight=None, C=1 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, class_weight=None, C=1, score=0.686714 -   1.9s\n",
      "[CV] solver=lbfgs, class_weight=None, C=1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... solver=lbfgs, class_weight=None, C=1, score=0.690606 -   0.7s\n",
      "[CV] solver=lbfgs, class_weight=None, C=1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... solver=lbfgs, class_weight=None, C=1, score=0.687661 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=None, C=1 ............................\n",
      "[CV] ... solver=lbfgs, class_weight=None, C=1, score=0.687284 -   0.6s\n",
      "[CV] solver=liblinear, class_weight=None, C=1 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=1, score=0.689880 -   0.3s\n",
      "[CV] solver=liblinear, class_weight=None, C=1 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=1, score=0.687661 -   0.3s\n",
      "[CV] solver=liblinear, class_weight=None, C=1 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=1, score=0.687107 -   0.3s\n",
      "[CV] solver=sag, class_weight=None, C=1 ..............................\n",
      "[CV] ..... solver=sag, class_weight=None, C=1, score=0.689880 -   2.4s\n",
      "[CV] solver=sag, class_weight=None, C=1 ..............................\n",
      "[CV] ..... solver=sag, class_weight=None, C=1, score=0.687934 -   2.4s\n",
      "[CV] solver=sag, class_weight=None, C=1 ..............................\n",
      "[CV] ..... solver=sag, class_weight=None, C=1, score=0.686714 -   2.3s\n",
      "[CV] solver=saga, class_weight=None, C=1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=1, score=0.689880 -   5.3s\n",
      "[CV] solver=saga, class_weight=None, C=1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=1, score=0.687934 -   5.4s\n",
      "[CV] solver=saga, class_weight=None, C=1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=1, score=0.686714 -   5.4s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=1, score=0.606447 -   2.0s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=1, score=0.606449 -   2.2s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=1, score=0.611046 -   1.6s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=1 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=1, score=0.607038 -   0.7s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=1 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=1, score=0.606090 -   0.7s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=1 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=1, score=0.610551 -   0.7s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=1, score=0.606680 -   0.3s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=1, score=0.606677 -   0.3s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=1 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=1, score=0.610562 -   0.4s\n",
      "[CV] solver=sag, class_weight=balanced, C=1 ..........................\n",
      "[CV] . solver=sag, class_weight=balanced, C=1, score=0.606571 -   2.4s\n",
      "[CV] solver=sag, class_weight=balanced, C=1 ..........................\n",
      "[CV] . solver=sag, class_weight=balanced, C=1, score=0.606449 -   2.2s\n",
      "[CV] solver=sag, class_weight=balanced, C=1 ..........................\n",
      "[CV] . solver=sag, class_weight=balanced, C=1, score=0.610921 -   2.5s\n",
      "[CV] solver=saga, class_weight=balanced, C=1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=1, score=0.606447 -   5.7s\n",
      "[CV] solver=saga, class_weight=balanced, C=1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=1, score=0.606449 -   6.2s\n",
      "[CV] solver=saga, class_weight=balanced, C=1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=1, score=0.611046 -   5.9s\n",
      "[CV] solver=newton-cg, class_weight=None, C=5 ........................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=5, score=0.690024 -   2.8s\n",
      "[CV] solver=newton-cg, class_weight=None, C=5 ........................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=5, score=0.686358 -   3.2s\n",
      "[CV] solver=newton-cg, class_weight=None, C=5 ........................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=5, score=0.687206 -   3.0s\n",
      "[CV] solver=lbfgs, class_weight=None, C=5 ............................\n",
      "[CV] ... solver=lbfgs, class_weight=None, C=5, score=0.690656 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=None, C=5 ............................\n",
      "[CV] ... solver=lbfgs, class_weight=None, C=5, score=0.685756 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=None, C=5 ............................\n",
      "[CV] ... solver=lbfgs, class_weight=None, C=5, score=0.686736 -   0.7s\n",
      "[CV] solver=liblinear, class_weight=None, C=5 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=5, score=0.690234 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=None, C=5 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=5, score=0.686572 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=None, C=5 ........................\n",
      "[CV]  solver=liblinear, class_weight=None, C=5, score=0.687206 -   0.6s\n",
      "[CV] solver=sag, class_weight=None, C=5 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... solver=sag, class_weight=None, C=5, score=0.690024 -   7.3s\n",
      "[CV] solver=sag, class_weight=None, C=5 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... solver=sag, class_weight=None, C=5, score=0.686358 -   5.1s\n",
      "[CV] solver=sag, class_weight=None, C=5 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... solver=sag, class_weight=None, C=5, score=0.687206 -   5.2s\n",
      "[CV] solver=saga, class_weight=None, C=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=5, score=0.690024 -   5.4s\n",
      "[CV] solver=saga, class_weight=None, C=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=5, score=0.686358 -   5.3s\n",
      "[CV] solver=saga, class_weight=None, C=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, class_weight=None, C=5, score=0.687206 -   5.6s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=5, score=0.606177 -   2.3s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=5, score=0.607009 -   2.3s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=5, score=0.611133 -   3.2s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=5 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=5, score=0.606418 -   1.0s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=5 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=5, score=0.607023 -   0.9s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=5 ........................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=5, score=0.610288 -   0.7s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=5, score=0.606053 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=5, score=0.607016 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=5 ....................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=5, score=0.611013 -   0.5s\n",
      "[CV] solver=sag, class_weight=balanced, C=5 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . solver=sag, class_weight=balanced, C=5, score=0.606177 -   4.9s\n",
      "[CV] solver=sag, class_weight=balanced, C=5 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . solver=sag, class_weight=balanced, C=5, score=0.607009 -   4.8s\n",
      "[CV] solver=sag, class_weight=balanced, C=5 ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . solver=sag, class_weight=balanced, C=5, score=0.611133 -   4.9s\n",
      "[CV] solver=saga, class_weight=balanced, C=5 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=5, score=0.606177 -   5.2s\n",
      "[CV] solver=saga, class_weight=balanced, C=5 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=5, score=0.607134 -   5.0s\n",
      "[CV] solver=saga, class_weight=balanced, C=5 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=5, score=0.611258 -   6.4s\n",
      "[CV] solver=newton-cg, class_weight=None, C=10 .......................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=10, score=0.690024 -   3.7s\n",
      "[CV] solver=newton-cg, class_weight=None, C=10 .......................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=10, score=0.685756 -   4.0s\n",
      "[CV] solver=newton-cg, class_weight=None, C=10 .......................\n",
      "[CV]  solver=newton-cg, class_weight=None, C=10, score=0.687343 -   3.9s\n",
      "[CV] solver=lbfgs, class_weight=None, C=10 ...........................\n",
      "[CV] .. solver=lbfgs, class_weight=None, C=10, score=0.689944 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=None, C=10 ...........................\n",
      "[CV] .. solver=lbfgs, class_weight=None, C=10, score=0.687349 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=None, C=10 ...........................\n",
      "[CV] .. solver=lbfgs, class_weight=None, C=10, score=0.687559 -   0.8s\n",
      "[CV] solver=liblinear, class_weight=None, C=10 .......................\n",
      "[CV]  solver=liblinear, class_weight=None, C=10, score=0.689813 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=None, C=10 .......................\n",
      "[CV]  solver=liblinear, class_weight=None, C=10, score=0.685932 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=None, C=10 .......................\n",
      "[CV]  solver=liblinear, class_weight=None, C=10, score=0.687343 -   0.5s\n",
      "[CV] solver=sag, class_weight=None, C=10 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=sag, class_weight=None, C=10, score=0.689813 -   5.4s\n",
      "[CV] solver=sag, class_weight=None, C=10 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=sag, class_weight=None, C=10, score=0.685756 -   4.7s\n",
      "[CV] solver=sag, class_weight=None, C=10 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=sag, class_weight=None, C=10, score=0.687343 -   4.6s\n",
      "[CV] solver=saga, class_weight=None, C=10 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... solver=saga, class_weight=None, C=10, score=0.689813 -   5.5s\n",
      "[CV] solver=saga, class_weight=None, C=10 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... solver=saga, class_weight=None, C=10, score=0.685756 -   5.6s\n",
      "[CV] solver=saga, class_weight=None, C=10 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... solver=saga, class_weight=None, C=10, score=0.687343 -   5.1s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=10, score=0.606294 -   2.6s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=10, score=0.606892 -   2.3s\n",
      "[CV] solver=newton-cg, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=newton-cg, class_weight=balanced, C=10, score=0.610768 -   2.5s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=10 .......................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=10, score=0.605725 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=10 .......................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=10, score=0.606788 -   0.8s\n",
      "[CV] solver=lbfgs, class_weight=balanced, C=10 .......................\n",
      "[CV]  solver=lbfgs, class_weight=balanced, C=10, score=0.610516 -   0.8s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=10, score=0.606294 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=10, score=0.607016 -   0.5s\n",
      "[CV] solver=liblinear, class_weight=balanced, C=10 ...................\n",
      "[CV]  solver=liblinear, class_weight=balanced, C=10, score=0.610768 -   0.6s\n",
      "[CV] solver=sag, class_weight=balanced, C=10 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, class_weight=balanced, C=10, score=0.606294 -   4.9s\n",
      "[CV] solver=sag, class_weight=balanced, C=10 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, class_weight=balanced, C=10, score=0.606892 -   4.9s\n",
      "[CV] solver=sag, class_weight=balanced, C=10 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, class_weight=balanced, C=10, score=0.610768 -   5.0s\n",
      "[CV] solver=saga, class_weight=balanced, C=10 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=10, score=0.606294 -   5.7s\n",
      "[CV] solver=saga, class_weight=balanced, C=10 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=10, score=0.606892 -   6.3s\n",
      "[CV] solver=saga, class_weight=balanced, C=10 ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbuck/venv/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, class_weight=balanced, C=10, score=0.610768 -   5.1s\n",
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8418\n",
      "F-score on testing data: 0.6912\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8419\n",
      "Final F-score on the testing data: 0.6915\n"
     ]
    }
   ],
   "source": [
    "# Importar 'GridSearchCV', 'make_scorer', e qualquer biblioteca necessária\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Inicializar o classificador\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Criar a lista de parâmetros que você quer otimizar, utilizando um dicionário, caso necessário.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = [{\n",
    "    'C': [1, 5, 10],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver' : ['liblinear', 'sag', 'saga']\n",
    "}]\n",
    "\n",
    "# Criar um objeto fbeta_score utilizando make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# Realizar uma busca grid no classificador utilizando o 'scorer' como o método de score no GridSearchCV() \n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer, verbose=5)\n",
    "\n",
    "# Adequar o objeto da busca grid como os dados para treinamento e encontrar os parâmetros ótimos utilizando fit() \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Recuperar o estimador\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Realizar predições utilizando o modelo não otimizado e modelar\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Reportar os scores de antes e de depois\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Validação final do modelo\n",
    "\n",
    "* Qual é a accuracy e o F-score do modelo otimizado utilizando os dados de testes?\n",
    "* Estes scores são melhores ou piores do que o modelo antes da otimização? \n",
    "* Como os resultados do modelo otimizado se comparam aos benchmarks do naive predictor que você encontrou na **Questão 1**?_\n",
    "\n",
    "**Nota:** Preencha a tabela abaixo com seus resultados e então responda as questões no campo **Resposta** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:\n",
    "\n",
    "|     Metric     | Unoptimized Model | Optimized Model | Naive Predictor |\n",
    "| :------------: | :---------------: | :-------------: | :-------------: | \n",
    "| Accuracy Score |0.8418|0.8419|0.2478|\n",
    "| F-score        |0.6912|0.6915|0.2917|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Os scores não apresentaram melhora significativa, indicando que o modelo da Regressão Logística não indica melhorar muito com o tuning. Isso é um indicativo de que vale a pena testar outros modelos pra ver se obtemo resultados superiores. Contudo, esses resultados são bem melhores que o Naive Predictor, como é mostrado na própria tabela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Importância dos atributos\n",
    "\n",
    "Uma tarefa importante quando realizamos aprendizado supervisionado em um conjunto de dados como os dados do censo que estudamos aqui é determinar quais atributos fornecem maior poder de predição. Focando no relacionamento entre alguns poucos atributos mais importantes e na label alvo nós simplificamos muito o nosso entendimento do fenômeno, que é a coisa mais importante a se fazer. No caso deste projeto, isso significa que nós queremos identificar um pequeno número de atributos que possuem maior chance de predizer se um indivíduo possui renda anual superior à \\$50,000.\n",
    "\n",
    "Escolha um classificador da scikit-learn (e.x.: adaboost, random forests) que possua o atributo `feature_importance_`, que é uma função que calcula o ranking de importância dos atributos de acordo com o classificador escolhido. Na próxima célula python ajuste este classificador para o conjunto de treinamento e utilize este atributo para determinar os 5 atributos mais importantes do conjunto de dados do censo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 6 - Observação da Relevância dos Atributos\n",
    "Quando **Exploramos os dados**, vimos que existem treze atributos disponíveis para cada registro nos dados do censo. Destes treze atributos, quais os 5 atributos que você acredita que são os mais importantes para predição e em que ordem você os ranquearia? Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**\n",
    "\n",
    "    1 capital-gain\n",
    "    2 capital-loss\n",
    "    3 education_level\n",
    "    4 education_num\n",
    "    5 occupation\n",
    "\n",
    "As duas primeiras características estão intimamente relacionadas com a renda do indivíduo. O ganho de capital está em primeiro lugar porque números maiores podem nos ajudar a identificar pessoas ganhando mais. A perda de capital ainda é importante, mas porque representa perda, pode nos dar alguns falsos positivos, isto é, indivíduos que já não ganham mais de 50.000,00. Os dois seguintes são indicativos do grau de instrução. É um fato bem conhecido que existe uma correlação positiva entre níveis mais altos de educação e salões maiores. Por último, algumas ocupações são mais bem pagas do que outras e esse recurso pode nos ajudar a identificar os indivíduos que ganham mais de 50.000,00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Extraindo a importância do atributo\n",
    "Escolha um algoritmo de aprendizado supervisionado da `sciki-learn` que possui o atributo `feature_importance_` disponível. Este atributo é uma função que ranqueia a importância de cada atributo dos registros do conjunto de dados quando realizamos predições baseadas no algoritmo escolhido.\n",
    "\n",
    "Na célula de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar um modelo de aprendizado supervisionado da sklearn se este for diferente dos três usados anteriormente. \n",
    " - Treinar o modelo supervisionado com todo o conjunto de treinamento.\n",
    " - Extrair a importância dos atributos utilizando `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8651\n",
      "Final F-score on the testing data: 0.7457\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAFgCAYAAAArYcg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158aff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importar um modelo de aprendizado supervisionado que tenha 'feature_importances_'\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Treinar o modelo utilizando o conjunto de treinamento com .fit(X_train, y_train)\n",
    "# PS: fiz o GridSearchCV e já estou usando os melhores parâmetros\n",
    "model = GradientBoostingClassifier(n_estimators=100, \n",
    "                                   learning_rate=1.0, \n",
    "                                   max_depth=1, \n",
    "                                   random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Realizar predições utilizando o modelo não otimizado e modelar\n",
    "best_predictions = model.predict(X_test)\n",
    "\n",
    "# Reportar os scores de antes e de depois\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "\n",
    "# Extrair a importância dos atributos utilizando .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Plotar\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 7 - Extraindo importância dos atributos\n",
    "\n",
    "Observe a visualização criada acima que exibe os cinco atributos mais relevantes para predizer se um indivíduo possui remuneração igual ou superior à \\$50,000 por ano.\n",
    "\n",
    "* Como estes cinco atributos se comparam com os 5 atributos que você discutiu na **Questão 6**? \n",
    "* Se você estivesse próximo da mesma resposta, como esta visualização confirma o seu raciocínio? \n",
    "* Se você não estava próximo, por que você acha que estes atributos são mais relevantes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:** a visualização mostra as cinco características mais relevantes para prever se um indivíduo ganha no máximo 50.000,00, no qual três parecem ser as mesmas discutidas na questão 6. Exceto por `age` e `hours-per-week`, todas as outras parecem confirmar as características mencionadas na questão 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando atributos\n",
    "\n",
    "Como um modelo performa se nós só utilizamos um subconjunto de todos os atributos disponíveis nos dados? Com menos atributos necessários para treinar, a expectativa é que o treinamento e a predição sejam executados em um tempo muito menor — com o custo da redução nas métricas de performance. A partir da visualização acima, nós vemos que os cinco atributos mais importantes contribuem para mais de 50% da importância de **todos** os atributos presentes nos dados. Isto indica que nós podemos tentar *reduzir os atributos* e simplificar a informação necessária para o modelo aprender. O código abaixo utilizará o mesmo modelo otimizado que você encontrou anteriormente e treinará o modelo com o mesmo conjunto de dados de treinamento, porém apenas com *os cinco atributos mais importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model trained on full data\n",
      "------\n",
      "Accuracy on testing data: 0.8651\n",
      "F-score on testing data: 0.7457\n",
      "\n",
      "Final Model trained on reduced data\n",
      "------\n",
      "Accuracy on testing data: 0.8355\n",
      "F-score on testing data: 0.6908\n"
     ]
    }
   ],
   "source": [
    "# Importar a funcionalidade para clonar um modelo\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduzir a quantidade de atributos\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Treinar o melhor modelo encontrado com a busca grid anterior\n",
    "clf = (clone(model)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Fazer novas predições\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Reportar os scores do modelo final utilizando as duas versões dos dados.\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 8 - Efeitos da seleção de atributos\n",
    "\n",
    "* Como o F-score do modelo final e o accuracy score do conjunto de dados reduzido utilizando apenas cinco atributos se compara aos mesmos indicadores utilizando todos os atributos? \n",
    "* Se o tempo de treinamento é uma variável importante, você consideraria utilizar os dados enxutos como seu conjunto de treinamento? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:** O F-score do modelo final nos dados reduzidos usando apenas cinco recursos parece ser muito menor do que os do modelo quando todos os recursos foram usados. No entanto, este não é o caso com precisão, embora a precisão também seja menor, não é muito menor que a do F-score. Considerando a precisão como métrica mais importante, considerando o tempo de treinamento como fator, podemos considerar o uso dos dados reduzidos como o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você tenha concluído toda a implementação de código e respondido cada uma das questões acima, você poderá finalizar o seu trabalho exportando o iPython Notebook como um documento HTML. Você pode fazer isso utilizando o menu acima navegando para \n",
    "**File -> Download as -> HTML (.html)**. Inclua este documento junto do seu notebook como sua submissão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
